{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffcdbaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding complete with SEED=1234\n"
     ]
    }
   ],
   "source": [
    "# Reproducibility setup\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "# 1) Python, NumPy, PyTorch seeds\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)  # if using multi-GPU\n",
    "\n",
    "# 2) CuDNN determinism settings (affects performance)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 3) Deterministic algorithms (PyTorch >= 1.8)\n",
    "try:\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "except Exception as e:\n",
    "    print(f\"Deterministic algorithms not fully available: {e}\")\n",
    "\n",
    "# 4) Optional: deterministic DataLoader shuffling\n",
    "torch_gen = torch.Generator()\n",
    "torch_gen.manual_seed(SEED)\n",
    "print(f\"Seeding complete with SEED={SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb1db161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.00538983  0.00411607  0.00210544 -0.00047868 -0.00016756\n",
      "    0.00064524  0.00287279  0.00056166  0.00216643  0.00080704]]]\n",
      "[[[0.06493099 0.04605467 0.04072821 0.03158877 0.02826946 0.02787655\n",
      "   0.04860585 0.02467423 0.0340929  0.0217407 ]]]\n",
      "0.00045595086117771453\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "N=10\n",
    "n_epochs = 40\n",
    "with open(f'processed_data_{N}.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    X_train = data['X_train']\n",
    "    y_train = data['y_train']\n",
    "    X_test = data['X_test']\n",
    "    y_test = data['y_test']\n",
    "    \n",
    "X_mean = X_train.mean(axis=(0, 1), keepdims=True)\n",
    "X_std  = X_train.std(axis=(0, 1), keepdims=True)\n",
    "\n",
    "print(X_mean)\n",
    "print(X_std)\n",
    "\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_test  = (X_test  - X_mean) / X_std\n",
    "\n",
    "X_train.shape\n",
    "\n",
    "# print\n",
    "y_mean = y_train.mean()\n",
    "\n",
    "print(y_mean)\n",
    "# y_std  = y_train.std()\n",
    "\n",
    "# y_train = (y_train - y_mean) / y_std\n",
    "# y_test  = (y_test  - y_mean) / y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaf407a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Data converted to tensors:\n",
      "X_train: torch.Size([563, 10, 10])\n",
      "y_train: torch.Size([563])\n",
      "Batch size: 16\n"
     ]
    }
   ],
   "source": [
    "# Build and train multivariate RNN model using PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "y_test_tensor = torch.FloatTensor(y_test).to(device)\n",
    "\n",
    "# Create DataLoader for batch training\n",
    "batch_size = 16\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"\\nData converted to tensors:\")\n",
    "print(f\"X_train: {X_train_tensor.shape}\")\n",
    "print(f\"y_train: {y_train_tensor.shape}\")\n",
    "print(f\"Batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57272681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCN(\n",
      "  (tcn): Sequential(\n",
      "    (0): TemporalBlock(\n",
      "      (conv1): Conv1d(10, 32, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "      (chomp1): Chomp1d()\n",
      "      (relu1): ReLU()\n",
      "      (dropout1): Dropout(p=0.3, inplace=False)\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "      (chomp2): Chomp1d()\n",
      "      (relu2): ReLU()\n",
      "      (dropout2): Dropout(p=0.3, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Conv1d(10, 32, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "        (1): Chomp1d()\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.3, inplace=False)\n",
      "        (4): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "        (5): Chomp1d()\n",
      "        (6): ReLU()\n",
      "        (7): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (downsample): Conv1d(10, 32, kernel_size=(1,), stride=(1,))\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): TemporalBlock(\n",
      "      (conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "      (chomp1): Chomp1d()\n",
      "      (relu1): ReLU()\n",
      "      (dropout1): Dropout(p=0.3, inplace=False)\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "      (chomp2): Chomp1d()\n",
      "      (relu2): ReLU()\n",
      "      (dropout2): Dropout(p=0.3, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "        (1): Chomp1d()\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.3, inplace=False)\n",
      "        (4): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
      "        (5): Chomp1d()\n",
      "        (6): ReLU()\n",
      "        (7): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): TemporalBlock(\n",
      "      (conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
      "      (chomp1): Chomp1d()\n",
      "      (relu1): ReLU()\n",
      "      (dropout1): Dropout(p=0.3, inplace=False)\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
      "      (chomp2): Chomp1d()\n",
      "      (relu2): ReLU()\n",
      "      (dropout2): Dropout(p=0.3, inplace=False)\n",
      "      (net): Sequential(\n",
      "        (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
      "        (1): Chomp1d()\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.3, inplace=False)\n",
      "        (4): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
      "        (5): Chomp1d()\n",
      "        (6): ReLU()\n",
      "        (7): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (linear): Sequential(\n",
      "    (0): Dropout(p=0.3, inplace=False)\n",
      "    (1): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([ 0.4328,  0.5869, -0.1300,  0.3185, -0.0096, -0.0306,  1.4274,  0.0814,\n",
      "         0.0317,  0.4489,  0.0602, -0.2767, -0.1376,  0.0956, -0.0854, -0.2011],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.2542,  0.2615,  0.0612, -0.1195,  0.3813,  0.1023, -0.1521, -0.0150,\n",
      "        -0.1078, -0.1009,  0.3378, -0.0784, -0.0907,  0.3708,  0.0895, -0.2932],\n",
      "       grad_fn=<SqueezeBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/dsml/lib/python3.13/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0161, -0.1246,  0.2432,  0.0661,  0.0942,  0.2497,  0.3526, -0.0709,\n",
      "         0.5114,  0.0165,  0.1448, -0.1099,  0.1366,  0.0484,  0.2520,  0.3844],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.2333,  0.2180, -0.2088,  0.0471, -0.0299, -0.4425,  0.1102, -0.1511,\n",
      "         0.1766, -0.3554, -0.2027, -0.0972,  0.0975,  0.1220,  0.0416, -0.0869],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1482, -0.0652, -0.0139,  0.0243,  0.3756,  0.2481,  0.0648, -0.1275,\n",
      "         0.0786,  0.1560,  0.1352, -0.0008,  0.4276,  0.2072, -0.1750, -0.0180],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.6453, -0.0743,  0.0896, -0.0127, -0.0827, -0.1268, -0.1171,  0.3628,\n",
      "         0.2104, -0.1471,  0.5225,  0.4445,  0.0113,  0.1390, -0.1434, -0.1485],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0652,  0.0329,  0.1681, -0.0853,  0.2622, -0.1402,  0.0040,  0.5156,\n",
      "        -0.0851,  0.3484,  0.0562, -0.1498, -0.0574,  0.2765, -0.1195,  0.2614],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0180, -0.1857, -0.1680,  0.8247,  0.0259,  0.0321,  0.1773, -0.1414,\n",
      "         0.0697, -0.0040, -0.0013,  0.1654, -0.1435,  0.1687, -0.1280,  0.1265],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.1681, -0.1279,  0.0378, -0.2338,  0.1127,  0.0845, -0.2912,  0.3105,\n",
      "        -0.1228, -0.1560,  0.6807, -0.2613, -0.3213,  0.1379,  0.2355, -0.2235],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0943, -0.0251,  0.2028, -0.2210, -0.0958,  0.0241, -0.0817, -0.2034,\n",
      "        -0.1632,  0.0481,  0.3780,  0.1807, -0.1176,  0.0993,  0.0676, -0.0850],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0390, -0.1537, -0.2077, -0.1507, -0.1470,  0.1983, -0.1927, -0.1605,\n",
      "        -0.2684, -0.1487, -0.1652, -0.0990, -0.1172, -0.1762, -0.0974,  0.1788],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.3185, -0.2407,  0.0157, -0.0613, -0.2438,  0.0614,  0.0079, -0.1604,\n",
      "        -0.0562, -0.0946, -0.1063, -0.0828, -0.1145, -0.1330, -0.0802, -0.1059],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0882, -0.0548, -0.1426, -0.0245,  0.0117, -0.1010, -0.0810,  0.0483,\n",
      "        -0.0778, -0.1787, -0.0910, -0.1553, -0.0631, -0.0647,  0.1549, -0.1487],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0141,  0.1766,  0.4546, -0.1486, -0.0154,  0.4386,  0.0117, -0.0339,\n",
      "        -0.0850, -0.3155, -0.1336, -0.2293,  0.1160, -0.1486, -0.1486,  0.2404],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1277, -0.1111,  0.2190, -0.1486, -0.1146, -0.1633,  0.0587, -0.1022,\n",
      "        -0.0335,  0.3199, -0.0984, -0.1974, -0.1139, -0.3848, -0.0522,  0.3201],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.1545,  0.0723,  0.4323,  0.2869, -0.2532, -0.1103,  0.3245, -0.1625,\n",
      "        -0.1263,  0.0462, -0.0145, -0.1492, -0.1558, -0.1226, -0.4640,  0.0186],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1091, -0.0713, -0.1787, -0.1091, -0.2477,  0.0411, -0.1419, -0.1373,\n",
      "         0.0686,  0.1808, -0.0675, -0.1144,  0.0085,  0.1717, -0.1180, -0.1570],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1239,  0.0125, -0.0738, -0.1681, -0.2206,  0.0499, -0.1185, -0.2615,\n",
      "        -0.1499, -0.1087, -0.1485, -0.0680, -0.0030, -0.1678, -0.3130, -0.3521],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0269, -0.1181, -0.2265, -0.1212, -0.1428, -0.1115,  1.1919, -0.1356,\n",
      "        -0.1477, -0.1656, -0.2272, -0.2183, -0.0338, -0.0335, -0.1714, -0.2376],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.2613, -0.0968, -0.1374, -0.0162,  0.0706, -0.2194, -0.1568, -0.0681,\n",
      "        -0.0499, -0.0315, -0.1511, -0.0561, -0.3132, -0.1583, -0.1313, -0.1280],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1035,  0.2280,  0.0628, -0.0614, -0.1377, -0.1985, -0.1439, -0.0977,\n",
      "        -0.0910, -0.2171,  0.4093,  0.1180, -0.1139, -0.0833, -0.0658, -0.0586],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1156, -0.1428, -0.1229,  0.0671, -0.1444, -0.1496, -0.1357, -0.0402,\n",
      "         0.3135,  0.0436,  1.8270, -0.0926, -0.1473,  0.0576, -0.0221, -0.0585],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0275, -0.1810, -0.1994, -0.1538, -0.1459, -0.1690, -0.0973, -0.0973,\n",
      "        -0.5147, -0.1352,  0.0696, -0.1600, -0.1241, -0.1459,  0.1031,  0.0177],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1208, -0.3198,  0.3681, -0.1453, -0.1878, -0.1512, -0.0985,  0.1961,\n",
      "        -0.0967,  0.0127,  0.1160, -0.1525,  0.1734, -0.2605, -0.1034, -0.1136],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1038, -0.0458, -0.1341, -0.1466, -0.0341, -0.0666,  0.0351, -0.1448,\n",
      "         0.0628,  0.1615,  0.4287,  0.0208,  0.1774, -0.1342,  0.1128, -0.1622],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1214,  0.0713, -0.0506, -0.1053, -0.0900, -0.2027, -0.1179,  0.0187,\n",
      "         0.0289,  0.1218, -0.1566, -0.0489, -0.0656, -0.1350, -0.1106,  0.0681],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.2334, -0.1363, -0.0490, -0.1418, -0.1831,  0.0053, -0.1704,  0.0047,\n",
      "        -0.1437,  0.2527, -0.0511,  0.1817, -0.1493,  0.2746,  0.2634, -0.0977],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.4356, -0.1293, -0.0183, -0.1497,  0.2974,  0.4061, -0.2758, -0.0900,\n",
      "        -0.1354, -0.3999, -0.0880, -0.1563, -0.1431, -0.0068, -0.1480,  0.6602],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1617, -0.2026, -0.0552], grad_fn=<SqueezeBackward1>)\n",
      "Epoch 1/20  Train: 5.373606e-02  Val: 2.714014e-02  Test: 1.435973e-02 ← best\n",
      "tensor([-0.1590, -0.1421,  0.1336, -0.1443, -0.1421, -0.1760, -0.1399,  0.0108,\n",
      "         0.0142, -0.1571, -0.0490, -0.1248, -0.1083, -0.2313,  0.2161,  0.2764],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1324, -0.1053, -0.1625, -0.1349, -0.1478, -0.1870,  0.0380,  0.1663,\n",
      "         0.0983, -0.0795, -0.0933, -0.1415, -0.0368, -0.1154, -0.1080, -0.1619],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.4192,  0.0636, -0.1196,  0.0883, -0.0910, -0.0718,  0.1978,  0.0712,\n",
      "        -0.1415, -0.1811, -0.1586, -0.1408, -0.0992, -0.0130, -0.1511, -0.1481],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1401, -0.0180, -0.1737, -0.0233,  0.0530, -0.1409, -0.0087, -0.1071,\n",
      "        -0.0288, -0.1309, -0.0855, -0.0800, -0.1328, -0.1401,  0.1826, -0.1866],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1549, -0.1394, -0.0753, -0.0888, -0.4404, -0.1269, -0.0651,  0.4835,\n",
      "        -0.0992,  0.0661, -0.2641,  0.3451, -0.2112, -0.1398, -0.1064,  0.0091],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.1008, -0.1858,  1.9565, -0.2607,  0.0728, -0.1179,  0.2432, -0.0036,\n",
      "        -0.0266, -0.0463,  0.0121, -0.0986, -0.0089, -0.2810, -0.1386,  0.0311],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1321, -0.1331, -0.0411, -0.1377, -0.0107, -0.1380,  0.0027,  0.0102,\n",
      "         0.0007,  0.0105, -0.1003, -0.1475, -0.1380,  0.0379, -0.1075, -0.1413],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0911, -0.1373,  0.0853, -0.1067,  0.0268, -0.1054, -0.0131,  0.1743,\n",
      "        -0.0711, -0.2038, -0.0279, -0.1920, -0.0188, -0.1374, -0.0528, -0.1442],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.2754, -1.2117,  0.1586, -0.0778, -0.1280, -0.1365, -0.3362, -0.0705,\n",
      "        -0.1125, -0.1365, -0.1365, -0.1714,  0.0686,  0.4027,  0.0767,  0.1046],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1358, -0.1358, -0.0842, -0.1421, -0.1358, -0.1076, -0.0541, -0.1449,\n",
      "        -0.0499, -0.0953, -0.1016,  0.1581, -0.1682, -0.4258,  0.1509,  0.0956],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1351, -0.0267, -0.1336, -0.1769, -0.0662,  0.0739, -0.0856,  0.0536,\n",
      "        -0.0571, -0.0757, -0.0611, -0.1145, -0.1066,  0.0581, -0.0498, -0.1634],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0655, -0.0987, -0.2206,  0.0070,  0.0751, -0.1343,  0.0296, -0.1343,\n",
      "        -0.0740,  0.1449, -0.1536,  0.0968, -0.0418,  0.0567, -0.0646,  0.0387],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0257, -0.1258, -0.0733, -0.1500, -0.1335, -0.1335,  0.0764, -0.1686,\n",
      "         0.0020, -0.0231, -0.1335,  0.1878, -0.1421, -0.0085, -0.1045, -0.0200],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0802,  0.0170, -0.1161,  0.1139, -0.1183, -0.0790, -0.0770, -0.1328,\n",
      "        -0.1984, -0.1328, -0.0214, -0.1230, -0.0194, -0.1328, -0.1328,  0.0378],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0553, -0.1320, -0.0770, -0.2267, -0.1205,  0.0399, -0.0082, -0.1120,\n",
      "        -0.1253, -0.0302, -0.0117, -0.0276, -0.0490, -0.1319, -0.1515,  0.2097],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1023, -0.1311, -0.0812, -0.1591, -0.0595,  0.1371, -0.0955, -0.1396,\n",
      "         0.0034,  0.0176, -0.0942, -0.0386,  0.0023, -0.1484, -0.1260, -0.1100],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0211, -0.0681, -0.0532, -0.1102, -0.1220,  0.0128, -0.1303,  0.1311,\n",
      "        -0.1095,  0.0986,  0.0155, -0.1303, -0.0898, -0.1055, -0.1058, -0.0226],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0915, -0.0545, -0.0369, -0.2067, -0.1354, -0.1295, -0.0857,  0.0863,\n",
      "        -0.0536, -0.2061,  0.0457, -0.1295, -0.0322, -0.1079, -0.1280,  0.2629],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0099, -0.0934, -0.0033, -0.1376,  0.0558, -0.0578,  0.0160,  0.0774,\n",
      "        -0.0456, -0.1287, -0.0774,  0.0029,  0.0121, -0.1009,  0.2793,  0.1900],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1771,  0.0316,  0.0472, -0.1216,  0.3918,  0.0193, -0.0880, -0.1314,\n",
      "        -0.0714, -0.1374, -0.0500, -0.0515, -0.1279, -0.1569, -0.0880,  0.0574],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1382, -0.0932, -0.2638, -0.1126, -0.1140, -0.0475, -0.0532, -0.1647,\n",
      "         0.3751, -0.1134, -0.0335, -0.0775, -0.0913, -0.1272, -0.0728,  0.0611],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0678, -0.0325, -0.1935, -0.0530, -0.0685, -0.1215, -0.0241,  0.2368,\n",
      "        -0.0055, -0.0165, -0.1168, -0.1264, -0.1811, -0.0011, -0.0498, -0.1264],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0560, -0.2724, -0.1010,  0.0108, -0.0995, -0.2036, -0.0783, -0.1365,\n",
      "        -0.1136, -0.0922, -0.0267, -0.0286, -0.1256, -0.1256, -0.1190, -0.1256],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0713,  0.1258, -0.1247, -0.1247, -0.1247, -0.0463, -0.0926, -0.1247,\n",
      "         0.0347, -0.1247,  0.2385,  0.0552, -0.1269,  0.1909,  0.0264, -0.0590],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0782, -0.0736, -0.0869, -0.0289, -0.1252,  0.0993,  0.1228, -0.0254,\n",
      "        -0.0264,  0.0898, -0.0296,  0.0045, -0.1384, -0.0500, -0.1239, -0.1143],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1553, -0.1231, -0.0194,  0.0672, -0.0726,  0.0079,  0.0431, -0.0821,\n",
      "        -0.0286, -0.0495, -0.0679, -0.1231,  0.0059, -0.0905, -0.0882, -0.0944],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0990, -0.2134, -0.2947, -0.1224, -0.0290,  0.3861, -0.1199, -0.0489,\n",
      "        -0.2430,  0.0565, -0.0612, -0.0645, -0.0605, -0.1179, -0.1289,  0.5480],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1105,  0.1896, -0.0767, -0.1097, -0.1219,  0.0548, -0.0232, -0.1216,\n",
      "         0.2782, -0.1173,  0.3484,  0.1465, -0.1216,  0.8396, -0.1216, -0.1216],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0909, -0.0877, -0.0222], grad_fn=<SqueezeBackward1>)\n",
      "Epoch 2/20  Train: 3.280876e-02  Val: 1.918313e-02  Test: 1.040099e-02 ← best\n",
      "tensor([-0.1175,  0.0858, -0.0995, -0.1318, -0.1203, -0.1203, -0.0753, -0.0053,\n",
      "        -0.1203,  0.1799, -0.1282, -0.0659, -0.1153, -0.1164, -0.1027, -0.0956],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1196, -0.1028, -0.0302, -0.1196,  0.1160, -0.1037, -0.1196, -0.1099,\n",
      "        -0.1196, -0.0835,  0.0334, -0.0963, -0.0432, -0.1718,  0.3645, -0.1196],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1089, -0.1235, -0.1189,  0.0258,  0.1130, -0.0767, -0.1189, -0.1255,\n",
      "        -0.1019,  0.2522,  0.4470, -0.0081, -0.2074, -0.1330, -0.1150, -0.1189],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0898, -0.0643,  0.0970,  0.1864, -0.0059,  0.0186, -0.0467,  0.1581,\n",
      "        -0.0521, -0.1212,  0.0415, -0.1182,  0.0277,  0.3947, -0.1164, -0.0518],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0884, -0.2527, -0.0113,  0.0014, -0.1299, -0.1278,  0.0831, -0.0680,\n",
      "        -0.0606, -0.0638, -0.0690, -0.0688, -0.0565,  0.4270, -0.1197,  0.0720],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1068, -0.0636, -0.0209, -0.0804, -0.0527, -0.0090, -0.1039, -0.0307,\n",
      "         0.0717,  0.0257, -0.1104, -0.0331, -0.1170, -0.0403, -0.1170, -0.0717],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.2371, -0.1164, -0.0792, -0.0907, -0.1164, -0.0578,  0.0295, -0.1258,\n",
      "        -0.1233, -0.0992, -0.1223, -0.1428,  0.1212,  0.1993, -0.1318, -0.0983],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0799, -0.1158, -0.0137, -0.1254, -0.0441, -0.1158, -0.1068, -0.0899,\n",
      "         0.0448, -0.0533, -0.1007,  0.0121, -0.0512, -0.2573, -0.0057, -0.0951],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0157, -0.1466, -0.0539, -0.0227, -0.1151,  0.1207, -0.0255, -0.0674,\n",
      "        -0.1061, -0.0284,  0.0559, -0.1129, -0.1151,  0.0880, -0.0022, -0.1151],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0246, -0.2376,  0.4835, -0.0609, -0.1185, -0.0558,  0.0409,  0.0363,\n",
      "        -0.1174, -0.0438, -0.1144, -0.0753, -0.1144,  0.0305,  0.0121, -0.0870],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0463, -0.0896, -0.1137, -0.0609, -0.0210, -0.0528, -0.0593, -0.0827,\n",
      "         0.0708, -0.1137, -0.1137, -0.0223,  0.3910, -0.1940, -0.0071, -0.0959],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0236,  0.0203, -0.0046,  0.2736,  0.0708, -0.1131, -0.0181,  0.0405,\n",
      "         0.1432, -0.0885, -0.0124, -0.0280, -0.1165, -0.1131,  0.1019, -0.0385],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0942, -0.1125,  0.5128, -0.0598, -0.0873,  0.0452, -0.0515, -0.1394,\n",
      "         0.0033,  0.0151, -0.2525,  0.0778,  0.0859, -0.1157, -0.1125, -0.1125],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0489, -0.0935,  0.0163, -0.2336, -0.1119, -0.1137, -0.1281, -0.1126,\n",
      "        -0.0153, -0.1119, -0.0945, -0.0680,  0.0109, -0.0372, -0.0722, -0.1142],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1137, -0.1113, -0.1113, -0.0836, -0.0186, -0.1113, -0.1113,  0.0535,\n",
      "        -0.0066, -0.1180, -0.1113, -0.1131,  0.0184, -0.1056, -0.1113, -0.0246],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1106, -0.0647, -0.0405, -0.2355,  0.0790,  0.0088, -0.0298, -0.0517,\n",
      "        -0.0044, -0.0542, -0.0625,  0.0389, -0.0567, -0.1106, -0.1077, -0.1106],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 7.6884e-02, -2.6647e-01, -1.0991e-01, -1.0991e-01, -5.2722e-02,\n",
      "        -4.4022e-02, -8.6976e-02, -8.4081e-02, -1.0991e-01,  7.6549e-02,\n",
      "        -7.8236e-02, -6.8605e-02, -8.8275e-02,  2.9488e-02, -6.7734e-02,\n",
      "         2.1405e-04], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1092, -0.0251,  0.2302, -0.0669, -0.1092,  0.0015, -0.0169, -0.0201,\n",
      "        -0.0290, -0.1424, -0.1103, -0.1092,  0.1395, -0.0470, -0.0273, -0.0840],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0854, -0.1085,  0.3227, -0.2124, -0.1085, -0.1091, -0.1011,  0.0405,\n",
      "        -0.0981, -0.1085, -0.0739, -0.0865, -0.1025, -0.1958, -0.0465, -0.0169],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1078, -0.0244, -0.0937,  0.0241, -0.0999, -0.0326, -0.0812,  0.0356,\n",
      "        -0.0545, -0.0906, -0.0712, -0.0819, -0.1078, -0.1690, -0.0278, -0.1078],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0492,  0.0304, -0.1078, -0.0512, -0.0627, -0.0977, -0.0759, -0.0254,\n",
      "        -0.1070, -0.0509, -0.0470, -0.1042, -0.0651, -0.1708, -0.0605, -0.1170],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0754, -0.1062,  0.0103, -0.0185, -0.0668, -0.0967,  0.0742, -0.0742,\n",
      "        -0.1062, -0.0937, -0.0644, -0.0091,  0.0991, -0.1062,  0.3331, -0.1062],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.3403,  0.0981, -0.0346, -0.0494, -0.0561,  0.0673, -0.0929, -0.1054,\n",
      "        -0.2084, -0.0650, -0.1054, -0.1876, -0.1054,  0.2903, -0.0907, -0.0846],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1269, -0.1046, -0.0705,  0.0458, -0.0307, -0.0607, -0.1500, -0.0030,\n",
      "        -0.1046,  0.0438,  0.0005, -0.1113, -0.1046, -0.1046, -0.0123, -0.1046],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0068, -0.1038, -0.1056, -0.0927, -0.1155,  0.2236, -0.1038, -0.1074,\n",
      "        -0.3760, -0.1038, -0.1038,  0.1211, -0.0940,  0.1990,  0.1079, -0.1041],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0634, -0.0563, -0.0714, -0.0224, -0.0928, -0.0949, -0.1001, -0.0257,\n",
      "        -0.0092,  0.1533,  0.0860, -0.1373, -0.0017, -0.0149, -0.1029,  0.5275],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1022,  0.0414, -0.0880, -0.1022, -0.1022, -0.0609, -0.1853, -0.1022,\n",
      "        -0.1022,  0.0687, -0.1044, -0.0849, -0.0597,  0.1233,  0.0673, -0.1083],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1014, -0.1016,  0.0201,  0.1899, -0.0699,  0.0774, -0.0667,  0.0087,\n",
      "        -0.1058, -0.0379, -0.0354, -0.1014, -0.1014, -0.0789, -0.1063, -0.1014],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0414, -0.1006, -0.1006], grad_fn=<SqueezeBackward1>)\n",
      "Epoch 3/20  Train: 1.429458e-02  Val: 1.055037e-02  Test: 7.166797e-03 ← best\n",
      "tensor([-0.1016, -0.0734, -0.0966, -0.0198, -0.0398, -0.0998,  0.0010, -0.0998,\n",
      "        -0.0606, -0.1512, -0.1002, -0.0998, -0.0998, -0.0954, -0.0998, -0.0998],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0775,  0.0240,  0.0022,  0.1228, -0.0948,  0.0301, -0.0752, -0.0858,\n",
      "         0.0245, -0.0664,  0.0945, -0.0154, -0.0063, -0.0373,  0.0573,  0.1735],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0572, -0.2903,  0.1993, -0.0260, -0.1038, -0.1087, -0.0982, -0.0982,\n",
      "        -0.0148, -0.0647, -0.1034, -0.2552, -0.0882, -0.2030,  0.2411, -0.0730],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0930, -0.0982, -0.0681,  0.0892,  0.0791, -0.0539,  0.0851,  0.0318,\n",
      "         0.1084,  0.2119, -0.0974, -0.0122, -0.0974, -0.0384, -0.0974,  0.0041],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1006, -0.0885, -0.0014, -0.0504, -0.0814, -0.0515, -0.0967, -0.0118,\n",
      "        -0.0967,  0.0397, -0.0117, -0.2236, -0.0577, -0.0967, -0.1227,  0.1351],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0964,  0.0120, -0.0959,  0.0103, -0.0959, -0.0227, -0.0923,  0.0004,\n",
      "        -0.1035, -0.0959, -0.0989,  0.2040, -0.0457, -0.0959, -0.0449,  0.1169],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0312, -0.0535, -0.0961, -0.0478,  0.0011, -0.0136, -0.0120, -0.0952,\n",
      "        -0.0952, -0.0703, -0.0091, -0.0952, -0.0952, -0.0430, -0.0952,  0.0037],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0802,  0.0089, -0.0590, -0.1001, -0.0020, -0.0412,  0.0826,  0.1185,\n",
      "        -0.0952, -0.0573, -0.0320, -0.0927, -0.0955, -0.0821, -0.0944, -0.0483],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0937, -0.0583, -0.0937, -0.0421, -0.0937, -0.1077,  0.2069, -0.0452,\n",
      "         0.0991, -0.0251, -0.0197, -0.0937, -0.0215,  0.0296, -0.1498, -0.0307],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0112, -0.0929,  0.2204, -0.0929, -0.0474, -0.0996,  0.1720,  0.0594,\n",
      "        -0.0428, -0.0172,  0.0495, -0.0932, -0.1100, -0.0443, -0.0391, -0.0929],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0315, -0.0922, -0.0922, -0.0566,  0.0050,  0.0230, -0.0597, -0.0834,\n",
      "        -0.0922, -0.0392, -0.0890,  0.1383, -0.0511, -0.0232, -0.0697, -0.0922],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0844, -0.0915, -0.0075, -0.1028,  0.0079, -0.0813, -0.0624, -0.0944,\n",
      "        -0.0915,  0.1571,  0.0185, -0.0915,  0.0160,  0.0221, -0.0586, -0.0284],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0124,  0.0011,  0.0745,  0.0128, -0.0820, -0.0908, -0.0787, -0.0908,\n",
      "        -0.0395, -0.1687, -0.0950, -0.0512, -0.1060, -0.0559,  0.0505, -0.0557],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0901, -0.0245,  0.0676,  0.1291, -0.0125,  0.0439, -0.0901,  0.0108,\n",
      "        -0.0901, -0.0654, -0.0745, -0.0755,  0.6372,  0.0805, -0.0901, -0.0596],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0891, -0.0810, -0.0609, -0.0677,  0.0987, -0.0895, -0.1238, -0.0895,\n",
      "        -0.0471, -0.0807, -0.0764, -0.0895, -0.0895,  0.0008, -0.0496, -0.0895],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0287, -0.0889,  0.0217, -0.0800, -0.0433, -0.0889, -0.0889, -0.0889,\n",
      "        -0.0056,  0.0758, -0.0077, -0.0591, -0.0906, -0.0889, -0.0889, -0.0746],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0077, -0.0094, -0.0159, -0.0476, -0.0682, -0.0125,  0.0096, -0.0450,\n",
      "        -0.0706, -0.0882, -0.0895,  0.0120, -0.0953, -0.0273, -0.1206, -0.0657],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0830, -0.0666, -0.0524, -0.0390, -0.0878,  0.1121, -0.0312, -0.0513,\n",
      "        -0.0875,  0.0278, -0.0391, -0.0322, -0.0875,  0.0822, -0.0240, -0.0875],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0322,  0.0161, -0.0701, -0.0868, -0.0743, -0.0233, -0.0868, -0.0868,\n",
      "        -0.0944, -0.0868,  0.0011, -0.0868, -0.0105, -0.0868,  0.0737, -0.0868],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0861, -0.0169, -0.0861,  0.0357,  0.2335, -0.0502, -0.1319, -0.0155,\n",
      "        -0.0890, -0.0215, -0.0861, -0.0722,  0.0456,  0.1461, -0.0897,  0.0838],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0925,  0.0841, -0.0855, -0.0664, -0.0855, -0.0855, -0.0807, -0.0778,\n",
      "        -0.0691,  0.0049, -0.0855,  0.0111, -0.0855, -0.0214, -0.0520, -0.0798],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0848, -0.1469, -0.0974,  0.0175, -0.0848,  0.0788, -0.0848, -0.0659,\n",
      "         0.1444, -0.0781, -0.0848,  0.1596,  0.0947, -0.0369, -0.0587, -0.0939],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0377,  0.0953, -0.0977, -0.0842, -0.0923, -0.0842,  0.0080, -0.0842,\n",
      "         0.0733,  0.0351, -0.0615, -0.0842,  0.0139, -0.0842, -0.0130, -0.0748],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0536, -0.0236, -0.0835, -0.0851,  0.0150, -0.1058, -0.0835, -0.0915,\n",
      "        -0.0882,  0.0529,  0.0585, -0.0348,  0.0929, -0.0322, -0.0354, -0.0835],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0428, -0.0829,  0.1182, -0.0453, -0.0829,  0.0195, -0.0028, -0.0548,\n",
      "        -0.0089, -0.0842,  0.1274, -0.0829, -0.0829,  0.0322,  0.0156, -0.0794],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0486, -0.0823, -0.0183, -0.0136, -0.0835, -0.0768, -0.0833, -0.0823,\n",
      "         0.0219, -0.0524,  0.0587, -0.0823,  0.1743, -0.0823, -0.0666,  0.0372],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.1092, -0.0324, -0.0817, -0.0991, -0.0817, -0.0109, -0.0817, -0.0817,\n",
      "        -0.0817, -0.0817, -0.0519, -0.0745, -0.0817, -0.0486, -0.0410, -0.0230],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-8.4613e-02,  1.0822e-02, -8.1020e-02, -1.2740e-05,  1.1415e-01,\n",
      "         6.6508e-02, -6.1378e-02, -8.1020e-02, -5.1317e-02,  4.3523e-02,\n",
      "         3.1086e-02, -1.8674e-02, -1.2824e-01, -2.3689e-01,  1.1297e-02,\n",
      "        -8.7456e-02], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0137, -0.0285, -0.0478], grad_fn=<SqueezeBackward1>)\n",
      "Epoch 4/20  Train: 8.329721e-03  Val: 7.177614e-03  Test: 4.506591e-03 ← best\n",
      "tensor([-0.0798, -0.0718,  0.1808, -0.0436, -0.1394, -0.0798, -0.0404, -0.0598,\n",
      "         0.0228,  0.0155,  0.0279,  0.0816, -0.0798,  0.1299, -0.0464,  0.0676],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0792,  0.0104,  0.0129,  0.1183, -0.0792, -0.0612,  0.3957, -0.3652,\n",
      "        -0.0770, -0.0792,  0.0091, -0.0376, -0.0593, -0.0378, -0.0792, -0.0792],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0658, -0.0701, -0.0367, -0.0455,  0.0050,  0.0039, -0.0853, -0.0786,\n",
      "        -0.0952,  0.0710, -0.0447, -0.0057, -0.0786,  0.1065, -0.0786, -0.0786],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0772, -0.0780, -0.0235, -0.0780,  0.0019, -0.0810, -0.0352, -0.0645,\n",
      "        -0.0584, -0.0423, -0.0145, -0.0780, -0.0574,  0.0476, -0.0780,  0.0137],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0044, -0.0212,  0.0622, -0.0774, -0.0074, -0.0819, -0.0630, -0.0046,\n",
      "        -0.1924,  0.0766, -0.0774,  0.4280,  0.0791, -0.0774,  0.0160, -0.0169],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0740, -0.0061, -0.0240, -0.0466, -0.0768, -0.0110, -0.0768,  0.0059,\n",
      "         0.0495, -0.0847, -0.0794, -0.0768, -0.0205, -0.0768, -0.0768, -0.1158],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.1466, -0.0239, -0.0451, -0.0763, -0.0763, -0.0763, -0.0416, -0.0763,\n",
      "        -0.0763,  0.0384, -0.0763, -0.0010, -0.0763, -0.0763, -0.0468,  0.1331],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0757, -0.0757, -0.0760,  0.0145, -0.1067, -0.0603,  0.0870,  0.1002,\n",
      "        -0.0822, -0.0310,  0.0826, -0.0029,  0.0446, -0.0477, -0.0394, -0.0774],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0013, -0.0751, -0.0575,  0.0125, -0.0337,  0.0306,  0.0194, -0.0269,\n",
      "         0.0161, -0.0814, -0.0751,  0.0033, -0.0751, -0.0839, -0.0768,  0.1351],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0746, -0.0695, -0.0746, -0.0634, -0.0609, -0.0333, -0.0746, -0.0746,\n",
      "        -0.0698, -0.0115, -0.0791, -0.0352,  0.0530, -0.0326, -0.0746, -0.0746],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0108, -0.0719, -0.0740,  0.0391, -0.0740, -0.0360, -0.0740, -0.0740,\n",
      "        -0.0740, -0.0285,  0.1048, -0.0658, -0.0395, -0.0740,  0.3236, -0.0740],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0673, -0.0642, -0.0569, -0.0735,  0.1054, -0.0572, -0.0735, -0.0983,\n",
      "        -0.0478, -0.0795, -0.0735, -0.0433, -0.0735, -0.2443, -0.0067, -0.0735],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0358,  0.0039, -0.0416, -0.0500, -0.1378, -0.0729, -0.0676, -0.0477,\n",
      "        -0.0480, -0.0729, -0.0729,  0.1440,  0.1516, -0.0729, -0.0666, -0.0454],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0804, -0.0384, -0.0018, -0.0723, -0.0723, -0.0723, -0.0723, -0.0760,\n",
      "         0.1351, -0.0362, -0.0286, -0.0712, -0.1392, -0.0348, -0.0723, -0.0723],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0023, -0.0716, -0.0716, -0.0716, -0.0531,  0.0502, -0.0716, -0.0849,\n",
      "        -0.0716, -0.0626, -0.0463,  0.1022,  0.1183, -0.0077, -0.0553, -0.0716],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0252, -0.0646, -0.0710, -0.0710, -0.0454,  0.0397,  0.2678,  0.0746,\n",
      "         0.1678, -0.0710, -0.0710, -0.0710, -0.0843, -0.0710, -0.0710,  0.0143],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0366, -0.0144,  0.0562, -0.1181, -0.0704,  0.1809, -0.0704, -0.0221,\n",
      "        -0.0704,  0.0757,  0.0077, -0.0718,  0.0023, -0.0503, -0.0165, -0.0313],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0698, -0.0698, -0.0728, -0.0698, -0.0784,  0.0840, -0.0698,  0.0414,\n",
      "        -0.0059, -0.0698, -0.0698, -0.0147, -0.0031, -0.0698,  0.0288,  0.0651],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0749, -0.0705, -0.0700, -0.0152, -0.0692, -0.0009, -0.0695,  0.0458,\n",
      "        -0.0692, -0.0141, -0.0692, -0.0829, -0.0692, -0.0692, -0.0692, -0.0338],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0342, -0.0686, -0.0460, -0.0686, -0.0350,  0.0585,  0.0013,  0.1703,\n",
      "         0.3591, -0.0295, -0.0234,  0.0548, -0.0455,  0.0421, -0.0528, -0.0355],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.1155,  0.1168,  0.2786,  0.0548, -0.0107, -0.1231, -0.0681, -0.0681,\n",
      "        -0.0681, -0.0430, -0.0681, -0.0681,  0.0056,  0.0435,  0.0076, -0.0715],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.1554,  0.0258, -0.0677, -0.0697, -0.0992, -0.0677,  0.0221, -0.0421,\n",
      "        -0.0623, -0.0677, -0.0677, -0.0820, -0.0585, -0.0466, -0.0089, -0.0677],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0672, -0.0089, -0.0342,  0.0377, -0.0672, -0.0263, -0.0346, -0.0672,\n",
      "         0.0611, -0.0044,  0.0102, -0.0687, -0.5462,  0.0418, -0.0672, -0.0665],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0244, -0.0531, -0.0269,  0.0956,  0.0013, -0.0667, -0.0667, -0.0241,\n",
      "         0.0563, -0.0608, -0.1530,  0.2145,  0.0763, -0.0150, -0.0372, -0.0283],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0123,  0.2637, -0.0662, -0.0456, -0.0110, -0.0662,  0.1734, -0.1403,\n",
      "        -0.0662,  0.0279,  0.0958,  0.1459,  0.1769,  0.0468, -0.0662, -0.0247],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0069, -0.0222,  0.0283, -0.0251,  0.0130, -0.0083, -0.0658,  0.0688,\n",
      "        -0.0658, -0.0691, -0.0455, -0.0658, -0.0658,  0.0034, -0.0658,  0.0555],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0130, -0.0565, -0.0654, -0.0603, -0.0654, -0.0654,  0.0400, -0.0654,\n",
      "        -0.0049,  0.0615, -0.0589, -0.0178,  0.0047,  0.1803, -0.0023,  0.0498],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0411, -0.0682, -0.0650, -0.0653,  0.0286, -0.0650, -0.0661, -0.0061,\n",
      "        -0.0650, -0.0650, -0.0650, -0.2388,  0.0420, -0.0506, -0.0198, -0.0337],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0878, -0.0645, -0.0645], grad_fn=<SqueezeBackward1>)\n",
      "Epoch 5/20  Train: 8.137068e-03  Val: 5.112030e-03  Test: 3.162496e-03 ← best\n",
      "tensor([-6.0958e-02, -1.2512e-01,  1.0763e-01, -5.4324e-02, -6.4016e-02,\n",
      "         1.0437e-02, -4.8157e-02, -1.0286e-04, -6.9293e-02, -6.4016e-02,\n",
      "        -6.4016e-02, -6.4016e-02,  5.5769e-03, -6.4016e-02, -1.3818e-02,\n",
      "        -6.4016e-02], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0357,  0.0574,  0.1579, -0.0635, -0.0296,  0.0255, -0.1379, -0.0635,\n",
      "        -0.0565, -0.0458, -0.0365, -0.0406, -0.0441,  0.0321,  0.0006, -0.0635],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0559, -0.0629, -0.0629, -0.0629, -0.0629, -0.0629, -0.0688,  0.0270,\n",
      "        -0.0629, -0.0174,  0.0165, -0.0629, -0.0629, -0.0629, -0.0629, -0.0629],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0624, -0.0338, -0.0364,  0.0995,  0.0076, -0.0624, -0.0624,  0.0155,\n",
      "        -0.0624, -0.0624, -0.0983, -0.0466, -0.0511,  0.1026,  0.0657, -0.2206],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0618, -0.0618, -0.0306, -0.0618,  0.0618,  0.0277, -0.0598, -0.0618,\n",
      "        -0.0618, -0.0618, -0.0618, -0.0580, -0.0618,  0.0400,  0.2359,  0.0653],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0562, -0.0612,  0.0081,  0.0137, -0.0095, -0.0442, -0.0212,  0.0972,\n",
      "        -0.0612, -0.0209, -0.0072, -0.0612, -0.0612,  0.0747, -0.0612,  0.0261],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0154, -0.0331, -0.0607, -0.0607,  0.0197,  0.0934, -0.0607, -0.0737,\n",
      "         0.0019, -0.0607, -0.0607, -0.0607,  0.0390, -0.0607, -0.0607, -0.0607],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0601, -0.0601, -0.0601, -0.0607, -0.0601, -0.0852,  0.0960,  0.0304,\n",
      "        -0.0601,  0.0527, -0.0601, -0.0601, -0.0533, -0.0790, -0.1585,  0.1352],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0596, -0.0596, -0.0084, -0.0326,  0.0069, -0.0596, -0.0165, -0.0596,\n",
      "        -0.0258, -0.0663, -0.0596, -0.0596,  0.0555, -0.0596, -0.0719, -0.0261],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0590,  0.0231, -0.0241, -0.0590, -0.0104, -0.0590, -0.0513, -0.0400,\n",
      "        -0.0590, -0.0590, -0.0590, -0.0260, -0.1023, -0.0590, -0.0510, -0.0212],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0619, -0.0584, -0.0584, -0.0584, -0.0584,  0.0537, -0.0047, -0.0623,\n",
      "         0.0089, -0.0264, -0.0591,  0.0620,  0.0340, -0.0484,  0.0875,  0.0312],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0283, -0.0156, -0.0761, -0.0578, -0.0470,  0.0498, -0.0578, -0.0578,\n",
      "        -0.0578, -0.0018, -0.0407, -0.0038,  0.0040, -0.0578,  0.0051, -0.0381],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0055, -0.0572,  0.0640, -0.0572, -0.0572, -0.0572, -0.0385, -0.0572,\n",
      "         0.0493, -0.0545, -0.0021,  0.0204,  0.1503, -0.0562, -0.0431, -0.0572],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0092, -0.0608,  0.0307, -0.0567, -0.0069, -0.0138, -0.0338, -0.0567,\n",
      "        -0.0567, -0.0567, -0.0567, -0.0026, -0.0405, -0.0622, -0.0567, -0.0193],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0561, -0.0561, -0.0561, -0.0363, -0.0184, -0.0648, -0.0561, -0.0561,\n",
      "        -0.0443, -0.0561, -0.0561, -0.0561, -0.0577, -0.0561,  0.0890,  0.0137],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0555, -0.0577,  0.0231, -0.0555, -0.0582, -0.0555, -0.0555, -0.0555,\n",
      "         0.0471,  0.1032,  0.0854, -0.0121,  0.0191, -0.0592, -0.0555, -0.0271],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0550, -0.0550, -0.0633, -0.0550, -0.0499, -0.0240, -0.0550, -0.0097,\n",
      "        -0.0213, -0.0316, -0.0550, -0.0550, -0.0525,  0.1563, -0.0070, -0.0550],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0544, -0.0283,  0.0006, -0.0544, -0.0544,  0.4027, -0.0008, -0.0142,\n",
      "        -0.0264, -0.0542, -0.0264, -0.0154, -0.0601, -0.0544, -0.0217, -0.0544],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0092,  0.1466, -0.0539, -0.0022, -0.0237, -0.0383, -0.0539, -0.0539,\n",
      "        -0.0154, -0.0631, -0.0539, -0.0539, -0.0539,  0.0276, -0.0539, -0.0295],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0810, -0.0534, -0.0065, -0.0534, -0.0534, -0.0517, -0.0114,  0.1858,\n",
      "        -0.0032,  0.0445, -0.0534,  0.0327,  0.0507,  0.0135, -0.0534,  0.0348],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0530, -0.0540,  0.0089, -0.0530, -0.0403, -0.0530, -0.0034, -0.0147,\n",
      "        -0.0627, -0.0597, -0.0530, -0.0530,  0.0140, -0.0023,  0.0307, -0.0282],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0280, -0.0525, -0.0447, -0.0366, -0.0422, -0.0525, -0.0525, -0.0725,\n",
      "        -0.0525, -0.0525, -0.0397, -0.0313, -0.0525,  0.0558, -0.0062, -0.0547],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0635,  0.0156, -0.0190,  0.0390, -0.0404, -0.0124, -0.0521, -0.0551,\n",
      "         0.0258, -0.0521, -0.0445, -0.0381,  0.0251, -0.0521, -0.0521,  0.2303],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0176, -0.0188, -0.0516,  0.0507,  0.0047, -0.0516,  0.0093, -0.0472,\n",
      "        -0.0454, -0.0516, -0.0516,  0.0589, -0.0516, -0.0516, -0.0516, -0.0516],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0366, -0.0512, -0.0255,  0.1042, -0.0512, -0.0512,  0.3904, -0.0416,\n",
      "        -0.0512, -0.0196,  0.0255,  0.0532, -0.0512, -0.0512, -0.0512, -0.0318],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0508, -0.0463, -0.0365, -0.0021,  0.1286, -0.0300, -0.0508, -0.0408,\n",
      "         0.0722,  0.0145,  0.0158, -0.0502, -0.0451, -0.0508, -0.0625, -0.0085],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0174, -0.0449, -0.0287, -0.0504, -0.0504, -0.0504, -0.0504, -0.0033,\n",
      "        -0.0504,  0.0280, -0.0504, -0.0398, -0.0238, -0.0504, -0.0504, -0.0504],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0328, -0.0481, -0.0500, -0.0138, -0.0700,  0.0173,  0.0057, -0.0301,\n",
      "        -0.0020, -0.0500, -0.4302, -0.0514, -0.0513,  0.0189, -0.0500, -0.0125],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0495, -0.0495, -0.0205], grad_fn=<SqueezeBackward1>)\n",
      "Epoch 6/20  Train: 5.127226e-03  Val: 3.701041e-03  Test: 2.093101e-03 ← best\n",
      "tensor([ 0.0547,  0.0036, -0.0099, -0.0490, -0.0490, -0.0490, -0.0228, -0.0490,\n",
      "        -0.0492,  0.1151, -0.0339, -0.0249,  0.1287, -0.0640, -0.0473, -0.0556],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0376, -0.0308, -0.0485,  0.0353, -0.0410, -0.0485,  0.0468, -0.0485,\n",
      "        -0.0485, -0.0488, -0.0300, -0.0485, -0.0545, -0.0485, -0.0418,  0.0095],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0188,  0.0198, -0.1008, -0.0393,  0.0257, -0.0367, -0.0203, -0.0480,\n",
      "        -0.0498, -0.0326, -0.0486, -0.0480, -0.0238, -0.0329, -0.0404, -0.0105],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0181,  0.1144, -0.0235, -0.0475,  0.0497,  0.1508, -0.0475, -0.0053,\n",
      "        -0.0475, -0.0322,  0.0184,  0.0185, -0.0391, -0.0229, -0.0475, -0.0087],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0471,  0.0061,  0.0273, -0.0471, -0.0471, -0.0132,  0.0193,  0.0073,\n",
      "        -0.0471, -0.0152, -0.0417, -0.0362, -0.0471, -0.0296,  0.0239, -0.0139],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0466, -0.0516,  0.0081,  0.0267, -0.0466, -0.0215, -0.0466, -0.0472,\n",
      "         0.1977, -0.0466, -0.0466, -0.0975, -0.0341, -0.0466, -0.0435, -0.0427],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0461,  0.0029, -0.0461, -0.0154, -0.0461, -0.0461, -0.0323, -0.0214,\n",
      "         0.0617,  0.0478, -0.0461,  0.0994,  0.0200, -0.0081,  0.1088,  0.0333],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0457, -0.0083, -0.0457, -0.0457,  0.0147, -0.0294, -0.0457, -0.0054,\n",
      "         0.0276, -0.0108, -0.0457, -0.0457, -0.0120, -0.0154, -0.0457, -0.0457],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0293,  0.0079,  0.0063,  0.0327, -0.0023, -0.0453, -0.0453, -0.0453,\n",
      "         0.0197,  0.0159, -0.0453, -0.0453, -0.0453, -0.0273, -0.0453, -0.0453],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.1247,  0.0566, -0.0448, -0.0448,  0.0004, -0.0277, -0.0222, -0.0448,\n",
      "        -0.0448, -0.0448, -0.1139, -0.0448, -0.0448, -0.0448, -0.0448, -0.0531],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0036, -0.0401, -0.0444, -0.0262, -0.0444, -0.0444, -0.0333, -0.0444,\n",
      "        -0.0444, -0.0443, -0.0416,  0.0172,  0.0530, -0.0485, -0.0472, -0.0444],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0290, -0.0440,  0.0080, -0.0337, -0.0430, -0.0440, -0.0440,  0.0481,\n",
      "        -0.0116, -0.0440,  0.0030, -0.0034, -0.0440, -0.0475, -0.0071, -0.0082],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0435, -0.0401, -0.0316, -0.0435, -0.0435, -0.0435, -0.0435,  0.0327,\n",
      "        -0.0425, -0.0435,  0.0179, -0.0435,  0.0801,  0.1946, -0.0435,  0.0078],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0431, -0.0253, -0.1253, -0.0431, -0.0177, -0.0373, -0.0329, -0.0162,\n",
      "        -0.0202, -0.0431,  0.0528,  0.0252, -0.0309, -0.0311,  0.0225, -0.0431],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0127, -0.0247, -0.0255, -0.0287, -0.0426,  0.0026, -0.0241, -0.0241,\n",
      "        -0.0279,  0.0123, -0.0426, -0.0426, -0.0343, -0.0426, -0.0302,  0.0202],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0422,  0.0021, -0.0440, -0.0422,  0.0275,  0.0149, -0.0422, -0.0422,\n",
      "        -0.0422, -0.0051, -0.0422,  0.1174, -0.0422, -0.0144, -0.0396, -0.0028],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0468, -0.0043,  0.1033,  0.0281, -0.0417, -0.0212, -0.0417,  0.0069,\n",
      "        -0.0417, -0.0211, -0.0435, -0.0417, -0.0417, -0.0069, -0.0422, -0.0109],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-4.1261e-02, -4.1399e-02, -4.1261e-02,  1.3177e-02, -4.1587e-02,\n",
      "        -4.1261e-02, -6.8557e-05,  4.5993e-02, -4.1261e-02, -4.1261e-02,\n",
      "        -5.3814e-03, -4.2184e-02, -3.4277e-02, -4.1261e-02, -4.1261e-02,\n",
      "        -6.7746e-03], grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.1444,  0.0239, -0.0415, -0.0408,  0.0352, -0.0408, -0.0408, -0.0218,\n",
      "        -0.0408,  0.0800, -0.0408, -0.0378,  0.0271, -0.0408, -0.0130,  0.0299],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0404, -0.0470,  0.0714,  0.0264,  0.0387, -0.0404, -0.0383, -0.0404,\n",
      "        -0.0404, -0.0404, -0.0142, -0.0374, -0.0404, -0.0634, -0.0404, -0.0404],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0400,  0.0453,  0.0343, -0.0400, -0.0402, -0.1370,  0.2518,  0.0504,\n",
      "        -0.0305, -0.0400, -0.0400, -0.0400, -0.0400, -0.0287,  0.0719, -0.0400],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0086,  0.0526, -0.0396, -0.0396, -0.0338, -0.0396, -0.0396, -0.0408,\n",
      "        -0.0186, -0.0189,  0.0028, -0.0396, -0.0396, -0.0396, -0.0216,  0.0817],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0392, -0.0392,  0.0179, -0.0581, -0.0173,  0.1741, -0.0392, -0.0392,\n",
      "         0.0263, -0.0392, -0.0616,  0.0819, -0.0305, -0.0375, -0.0392, -0.0392],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0172, -0.0245, -0.0171,  0.0886, -0.0388, -0.0388, -0.0388, -0.0388,\n",
      "         0.1257, -0.0388, -0.0388, -0.0662, -0.0224, -0.0388,  0.0633, -0.0099],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0384, -0.0312, -0.0187, -0.0384, -0.0384, -0.0187, -0.0384, -0.0384,\n",
      "         0.2239, -0.0384,  0.0328, -0.0384, -0.0083,  0.1271,  0.0085, -0.0384],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0381, -0.0179,  0.2399, -0.0381, -0.0751,  0.1075, -0.0381, -0.0381,\n",
      "        -0.0416, -0.0281, -0.0381, -0.0018, -0.0381, -0.0381,  0.0592, -0.0106],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0379, -0.0379,  0.0077, -0.0379, -0.1604, -0.0379, -0.0338, -0.0379,\n",
      "        -0.0192,  0.0728, -0.0072, -0.0379,  0.0822, -0.0379, -0.0379, -0.0383],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0375, -0.0375, -0.0375,  0.0038, -0.0375, -0.0316, -0.0375,  0.0121,\n",
      "        -0.0201, -0.0375, -0.0251,  0.1298, -0.0371, -0.0844,  0.0002, -0.0375],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0372, -0.0212, -0.0372], grad_fn=<SqueezeBackward1>)\n",
      "Epoch 7/20  Train: 2.947161e-03  Val: 3.262951e-03  Test: 1.392148e-03 ← best\n",
      "tensor([ 0.0008,  0.0481, -0.0369, -0.0369,  0.0722, -0.0369, -0.0311, -0.0369,\n",
      "        -0.0075, -0.0004,  0.1369, -0.0345, -0.0369, -0.0369, -0.0369,  0.0143],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0366, -0.0138, -0.0004, -0.0421, -0.0366, -0.0366, -0.0366, -0.0329,\n",
      "        -0.0333, -0.0366, -0.0210,  0.0236, -0.0139, -0.0175, -0.0366, -0.0366],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0362, -0.0362, -0.0362, -0.0362, -0.0341, -0.0362,  0.0215, -0.0219,\n",
      "         0.0283, -0.0362, -0.0362,  0.0201, -0.0362, -0.0362,  0.1581, -0.0362],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0359, -0.0359,  0.0215, -0.0321, -0.0359, -0.0359,  0.2703, -0.0359,\n",
      "        -0.0359, -0.0463, -0.0359,  0.0409, -0.0359, -0.0123, -0.0359,  0.0100],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0185, -0.0356, -0.0356, -0.0356, -0.0356,  0.0305, -0.0372, -0.0356,\n",
      "         0.2039, -0.0227, -0.0356, -0.0356, -0.0356, -0.0356, -0.0356, -0.0356],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0378, -0.0353, -0.0353,  0.0608, -0.0058, -0.0353, -0.0353, -0.0353,\n",
      "        -0.0353, -0.0353, -0.0353,  0.0014,  0.0266, -0.0353, -0.0353, -0.0383],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-3.5027e-02, -2.7782e-02,  1.8577e-02, -1.0612e-03,  1.6970e-02,\n",
      "        -3.7632e-02, -3.5027e-02, -3.5027e-02, -9.6001e-05, -3.5027e-02,\n",
      "        -3.5027e-02,  5.5748e-02, -1.0577e-02,  3.8715e-02, -3.5027e-02,\n",
      "        -3.5027e-02], grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0370,  0.1170, -0.0415, -0.0405, -0.0347, -0.0347, -0.0368, -0.0372,\n",
      "         0.0100,  0.0812, -0.0347, -0.0228, -0.0329, -0.0091, -0.0347, -0.0347],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0241,  0.0560, -0.0309, -0.0047, -0.0207, -0.0265, -0.0317,  0.0065,\n",
      "         0.0217, -0.0198,  0.0658, -0.0330,  0.0279, -0.0064, -0.0348, -0.0031],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0342, -0.0342,  0.0499, -0.0208, -0.0323, -0.0342,  0.0167,  0.0509,\n",
      "        -0.0342, -0.0308, -0.0342, -0.0342, -0.0342, -0.0173, -0.0342, -0.0342],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0339, -0.0339, -0.0339, -0.0033, -0.0339, -0.0135, -0.0339,  0.0400,\n",
      "        -0.0406, -0.0339, -0.0339, -0.0339,  0.0164,  0.0320, -0.0110, -0.0339],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0723, -0.0336, -0.0336,  0.0232, -0.0336, -0.0324, -0.0353, -0.0106,\n",
      "         0.0370, -0.0336, -0.0336, -0.0336,  0.0418, -0.0336, -0.0098,  0.0443],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0041, -0.0333, -0.0339, -0.0216, -0.0333,  0.0334,  0.0751, -0.0333,\n",
      "        -0.0010, -0.0268, -0.0333, -0.0191, -0.0274, -0.0143,  0.0316, -0.0333],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0319, -0.0250, -0.0331, -0.0331, -0.0258, -0.0331, -0.0331, -0.0331,\n",
      "         0.0601, -0.0331,  0.0112,  0.0016, -0.0331, -0.0331, -0.0331, -0.0331],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0362, -0.0328, -0.0328, -0.0336, -0.0328, -0.0328,  0.1681, -0.0328,\n",
      "         0.0120, -0.0328, -0.0328, -0.0328, -0.0102, -0.0115,  0.0251, -0.0328],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0330,  0.0124, -0.0325, -0.0070, -0.0020, -0.0325, -0.0325, -0.0236,\n",
      "        -0.0325,  0.0164, -0.0351,  0.0207,  0.0148, -0.0336, -0.0325, -0.0316],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 2.8244e-02, -3.2760e-02, -3.2259e-02,  2.1736e-02, -2.2852e-02,\n",
      "        -3.2259e-02, -3.2259e-02, -3.2259e-02,  1.0310e-02, -3.2259e-02,\n",
      "        -2.6204e-05, -4.1529e-02, -3.2259e-02, -3.2259e-02, -1.3658e-03,\n",
      "         2.0981e-02], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0289, -0.0139, -0.0203, -0.0197, -0.0050, -0.0320, -0.0320, -0.0320,\n",
      "        -0.0347,  0.0077, -0.0320, -0.0288,  0.1832, -0.0007, -0.0235, -0.0032],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.1445, -0.0317, -0.0172, -0.0067,  0.0438, -0.0317,  0.0031, -0.0217,\n",
      "        -0.0390,  0.1121, -0.0317, -0.0317, -0.0317, -0.0112, -0.0317,  0.0336],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0314, -0.0314, -0.0204, -0.0089, -0.0314, -0.0134, -0.0314, -0.0314,\n",
      "        -0.0314, -0.0314, -0.0314, -0.1239, -0.0414, -0.0006, -0.0314, -0.0015],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0032, -0.0311, -0.0311, -0.0132, -0.0246, -0.0311, -0.0004, -0.0311,\n",
      "        -0.0113, -0.0081, -0.0311, -0.0311, -0.0311, -0.0153, -0.0251, -0.0311],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0308,  0.0399, -0.0815, -0.0308, -0.0308, -0.0308, -0.0578, -0.0308,\n",
      "        -0.0308,  0.0391, -0.0173, -0.0189,  0.0021, -0.0308, -0.0920, -0.0257],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0304,  0.0308,  0.3426,  0.0886, -0.0297, -0.0318, -0.0304, -0.0304,\n",
      "        -0.0018, -0.0304, -0.0183, -0.0304, -0.0304,  0.1579,  0.2861, -0.0283],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0302,  0.0116,  0.0076, -0.0085, -0.0308, -0.0272, -0.0302, -0.0302,\n",
      "        -0.0302, -0.0086, -0.0302, -0.0351, -0.0302, -0.0302, -0.0179,  0.1333],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0299, -0.0299, -0.0299,  0.1028,  0.0126,  0.0150, -0.0299, -0.0311,\n",
      "         0.1131, -0.0299, -0.0299,  0.0544, -0.0299, -0.0299, -0.0622, -0.0124],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0181, -0.0296, -0.0296, -0.0551, -0.0234, -0.0296, -0.0296, -0.0296,\n",
      "        -0.0296,  0.1074,  0.0313, -0.0174, -0.0296, -0.0296, -0.0296, -0.0412],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0116, -0.0294, -0.0294,  0.4094, -0.0294, -0.0141, -0.0294, -0.0294,\n",
      "        -0.0018, -0.0287,  0.0187, -0.0294,  0.0469,  0.0467, -0.0294, -0.0133],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0265, -0.0292, -0.0194, -0.0160, -0.0292, -0.0430, -0.0308, -0.0292,\n",
      "        -0.0019, -0.0159, -0.0292, -0.0292, -0.0292, -0.0292, -0.0044, -0.0292],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0290, -0.0290, -0.0290], grad_fn=<SqueezeBackward1>)\n",
      "Epoch 8/20  Train: 2.999068e-03  Val: 2.218091e-03  Test: 9.665230e-04 ← best\n",
      "tensor([-0.0287, -0.0287,  0.0043,  0.0600,  0.0449, -0.0287,  0.0333, -0.0287,\n",
      "        -0.0287, -0.1928, -0.0287, -0.0287,  0.0773, -0.0287, -0.0287, -0.0025],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0284, -0.0284, -0.0010, -0.0284,  0.0217,  0.1244, -0.0220, -0.0284,\n",
      "        -0.0284,  0.0252, -0.0284, -0.0280, -0.0284, -0.0324, -0.0284, -0.0149],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0432,  0.0069, -0.0281,  0.0065, -0.0281, -0.0084, -0.0010, -0.0164,\n",
      "        -0.0207, -0.0281, -0.0281, -0.0292, -0.0125,  0.0616, -0.0281, -0.0281],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0278, -0.0099,  0.0618, -0.0278,  0.0372, -0.0278, -0.0278, -0.0348,\n",
      "        -0.0278, -0.0278, -0.0278,  0.0050,  0.0070,  0.0173, -0.0278, -0.0278],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0281, -0.0275, -0.0295,  0.0133, -0.0275, -0.0275, -0.0275, -0.0275,\n",
      "        -0.0234, -0.0275, -0.0275, -0.0275, -0.0275, -0.0275, -0.0275, -0.0275],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0272, -0.0640, -0.0034, -0.0272, -0.0070, -0.0272, -0.0272,  0.0673,\n",
      "        -0.0399, -0.0251,  0.0461, -0.0272,  0.0019, -0.0272, -0.0272, -0.0272],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0082, -0.0269, -0.0269, -0.0269, -0.0269, -0.0066,  0.0531, -0.0269,\n",
      "        -0.0269, -0.0049, -0.0269,  0.0444, -0.0269, -0.0269,  0.0263, -0.0269],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0110, -0.0221, -0.0177, -0.0620, -0.0266, -0.0266, -0.0266, -0.0266,\n",
      "         0.0654, -0.0266, -0.0219,  0.0012, -0.0266,  0.0432, -0.0264, -0.0266],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0263, -0.0263, -0.0263, -0.0305, -0.0343, -0.0263, -0.0213,  0.0100,\n",
      "         0.0112, -0.1101, -0.0181, -0.0263, -0.0245, -0.0669, -0.0186,  0.0269],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0259, -0.0259,  0.0782,  0.0018, -0.0041,  0.0566, -0.0018, -0.0259,\n",
      "         0.0789, -0.0259, -0.0259, -0.0259, -0.0259, -0.0259, -0.0339, -0.0099],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0256, -0.0517, -0.0256, -0.0027, -0.0356, -0.0256, -0.0188, -0.0256,\n",
      "        -0.0256, -0.0256, -0.0256, -0.0256, -0.0256,  0.0435, -0.0264, -0.0335],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0253,  0.0415, -0.0113, -0.0253, -0.0253,  0.0684, -0.0253, -0.0253,\n",
      "        -0.0253, -0.0253, -0.0253,  0.0825, -0.0285, -0.0253, -0.0253,  0.0279],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0621, -0.0250, -0.0250,  0.0041,  0.0269,  0.0223, -0.0203, -0.0250,\n",
      "        -0.0250, -0.0250, -0.0250, -0.0250, -0.0250,  0.0750,  0.0138,  0.4175],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0247, -0.0154, -0.0199,  0.0278, -0.0247, -0.0247, -0.0247, -0.0247,\n",
      "         0.1061,  0.0541, -0.0259, -0.0009,  0.0122,  0.0055,  0.0136, -0.0247],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0236, -0.0245, -0.0245, -0.0245, -0.0245, -0.0245, -0.0245, -0.0259,\n",
      "        -0.0003,  0.0193, -0.0245, -0.0048, -0.0036, -0.0245, -0.0245, -0.0245],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0218, -0.0243, -0.0243,  0.0076, -0.0247,  0.0179, -0.0243, -0.0176,\n",
      "        -0.0243, -0.0243, -0.0243, -0.0175,  0.0671, -0.0118, -0.0357, -0.0243],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0003, -0.0241, -0.0241, -0.0241,  0.0224, -0.0382, -0.0241, -0.0241,\n",
      "        -0.0241, -0.0241, -0.0241, -0.0173, -0.0038,  0.0025, -0.0241, -0.0241],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0238,  0.0117,  0.0097, -0.0238, -0.0238, -0.0238, -0.0238, -0.0179,\n",
      "         0.0203, -0.0238, -0.0238, -0.0238, -0.0238, -0.0238, -0.0134, -0.0181],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0498, -0.0235, -0.0235,  0.0433, -0.0235, -0.0235, -0.0235, -0.0066,\n",
      "         0.0031, -0.0860, -0.0235,  0.0139, -0.0235,  0.0492, -0.0235, -0.0235],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0233,  0.0082, -0.0230,  0.0003, -0.0233,  0.0047,  0.0032,  0.0515,\n",
      "        -0.0233, -0.0233, -0.0223, -0.0233, -0.0233, -0.0270, -0.0233, -0.0233],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0230, -0.0230, -0.0230,  0.0076, -0.0045, -0.0230, -0.0230,  0.2030,\n",
      "        -0.0129, -0.0230, -0.0204, -0.0223, -0.0609, -0.0138,  0.0728, -0.0230],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0538,  0.0425, -0.0160, -0.0254, -0.0316, -0.0227, -0.0181, -0.0155,\n",
      "        -0.0227, -0.0227, -0.0025, -0.0227,  0.0150, -0.0227, -0.0219, -0.0227],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0224,  0.0194, -0.0224, -0.0204, -0.0168, -0.0224,  0.0024,  0.0924,\n",
      "        -0.0224, -0.0224, -0.0224, -0.0224,  0.0492, -0.0121, -0.0304,  0.0010],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0222, -0.0222,  0.0852, -0.0222,  0.0172,  0.0899, -0.0222,  0.2387,\n",
      "        -0.0153, -0.0091, -0.0222, -0.0222, -0.0222, -0.0177,  0.0112, -0.0222],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0220, -0.0220,  0.0178, -0.0220, -0.0220, -0.0220,  0.0220, -0.0220,\n",
      "        -0.0170, -0.0056, -0.0197, -0.0220, -0.0220, -0.0220,  0.0088,  0.0363],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0218, -0.0218, -0.0218, -0.0218, -0.0218,  0.0168, -0.0218, -0.0218,\n",
      "         0.0491, -0.0218, -0.0218, -0.0218, -0.0218, -0.0218, -0.0218,  0.0513],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0216, -0.0037, -0.0216, -0.0216, -0.0216, -0.0216, -0.0216,  0.0526,\n",
      "         0.0314, -0.0020, -0.0216, -0.0216, -0.0216,  0.0108, -0.0216,  0.0028],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0681, -0.0214, -0.0214, -0.0214,  0.0068, -0.0117, -0.0214, -0.0214,\n",
      "        -0.0129, -0.0214, -0.0263, -0.0214, -0.0253, -0.0023, -0.0214, -0.0214],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0212, -0.0212, -0.0212], grad_fn=<SqueezeBackward1>)\n",
      "Epoch 9/20  Train: 2.097209e-03  Val: 1.271315e-03  Test: 6.277673e-04 ← best\n",
      "tensor([ 0.0192, -0.0209, -0.0058, -0.0226, -0.0209,  0.0070, -0.0209,  0.0129,\n",
      "        -0.0209, -0.0209, -0.0209, -0.0047, -0.0131, -0.0043, -0.0197,  0.0377],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0220, -0.0207, -0.0207,  0.1704,  0.0112,  0.0071, -0.0207, -0.0207,\n",
      "        -0.0207, -0.0207, -0.0207, -0.0207, -0.0317, -0.0317, -0.0008,  0.0864],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0546,  0.0388, -0.0205, -0.0205, -0.0205, -0.0205, -0.0197, -0.0649,\n",
      "        -0.0092, -0.0060, -0.0205, -0.0205, -0.0205,  0.0763, -0.0205, -0.0110],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0203, -0.0203, -0.0203, -0.0203, -0.0203, -0.0203, -0.0203, -0.0203,\n",
      "        -0.0203, -0.0203, -0.0203, -0.0203, -0.0203,  0.1110, -0.0203, -0.0203],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-2.0085e-02, -2.0085e-02,  9.0203e-04, -2.0085e-02, -2.9694e-05,\n",
      "        -1.7340e-02, -2.0085e-02, -2.0085e-02, -1.6668e-02, -2.0085e-02,\n",
      "        -2.0085e-02,  1.8588e-02, -2.0085e-02, -2.0085e-02, -2.2362e-02,\n",
      "        -2.0085e-02], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0310,  0.0049, -0.0199, -0.0199,  0.0250, -0.0190, -0.0199, -0.0199,\n",
      "        -0.0118,  0.0128, -0.0199, -0.0199, -0.0199, -0.0236,  0.0121,  0.0459],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0196, -0.0108, -0.0196, -0.0264, -0.0196, -0.0179, -0.0196, -0.0196,\n",
      "        -0.0196,  0.0097, -0.0138, -0.0196, -0.0196,  0.0050, -0.0196, -0.0196],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0011, -0.0193, -0.0274, -0.0193, -0.0193, -0.0193, -0.0193, -0.0214,\n",
      "        -0.0038, -0.0193, -0.0078, -0.0193, -0.0193, -0.0193, -0.0193, -0.0243],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0191,  0.0187, -0.0045, -0.0191, -0.0191, -0.0191, -0.0191, -0.0216,\n",
      "        -0.0191,  0.1361, -0.0166, -0.0274,  0.0131, -0.0191, -0.0191, -0.0323],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0188, -0.0188, -0.0189, -0.0012, -0.0188, -0.0188,  0.0113,  0.0143,\n",
      "        -0.0188, -0.0188, -0.0044, -0.0027, -0.0188, -0.0135, -0.0181, -0.0188],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0038, -0.0289, -0.0186, -0.0186, -0.0186, -0.0186, -0.0186, -0.0186,\n",
      "        -0.0497, -0.0074, -0.0020,  0.0309, -0.0186, -0.0186, -0.0186,  0.0232],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0183, -0.0183, -0.0061, -0.0183, -0.0183, -0.0144, -0.0183, -0.0218,\n",
      "        -0.0183, -0.0141, -0.0102, -0.0183, -0.0183, -0.0078, -0.0183, -0.0060],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0180, -0.0182, -0.0180, -0.0180, -0.0180,  0.0036, -0.0064, -0.0180,\n",
      "        -0.0180, -0.0180, -0.0010, -0.0180, -0.0180, -0.0176, -0.0449, -0.0099],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0458, -0.0183,  0.0054, -0.0177, -0.0504, -0.0177, -0.0205, -0.0020,\n",
      "        -0.0186, -0.0177,  0.0171, -0.0177, -0.0177, -0.0114, -0.0200,  0.0614],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0203,  0.0166, -0.0174, -0.0174, -0.0070, -0.0779, -0.0167, -0.0174,\n",
      "        -0.0183, -0.0174, -0.0174, -0.0174, -0.0174,  0.0730, -0.0174,  0.0338],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1634, -0.0172,  0.0164, -0.0171, -0.0151, -0.0090, -0.0171, -0.0269,\n",
      "        -0.0171, -0.0265,  0.0294, -0.0171, -0.0171, -0.0171, -0.0171, -0.0198],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0149, -0.0169, -0.0169,  0.0736, -0.0169,  0.0124,  0.0573,  0.0098,\n",
      "         0.0559, -0.0169,  0.0610, -0.0169, -0.0204, -0.0169, -0.0169, -0.0169],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0345, -0.0166,  0.0829, -0.0194, -0.0166, -0.0166, -0.0166, -0.0166,\n",
      "         0.1120, -0.0171,  0.0414, -0.0166,  0.1423,  0.0276,  0.0045, -0.0166],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0365, -0.0164, -0.0164, -0.0241,  0.0023, -0.0164, -0.0164, -0.0164,\n",
      "        -0.0052, -0.0164,  0.0436, -0.0164, -0.0164, -0.0164, -0.0083,  0.0126],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0162,  0.0228, -0.0162,  0.0403, -0.0162, -0.0162, -0.0162, -0.0162,\n",
      "        -0.0179,  0.0562, -0.0157, -0.0162, -0.0162, -0.0149,  0.0103, -0.0162],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0674, -0.0122, -0.0160,  0.1652, -0.0160, -0.0160, -0.0087, -0.0138,\n",
      "        -0.0160,  0.0578, -0.0160,  0.0624, -0.0160, -0.0160, -0.0135, -0.0054],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0178,  0.0184,  0.0006, -0.0158, -0.0158, -0.0158,  0.0402,  0.0253,\n",
      "        -0.0060,  0.0702,  0.0338, -0.0032, -0.0143, -0.1011, -0.0158, -0.0158],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0030, -0.0156,  0.0465,  0.0180, -0.0156, -0.0157, -0.0156, -0.0156,\n",
      "         0.0291, -0.0156, -0.0156, -0.0156,  0.0750, -0.0156, -0.0156, -0.0156],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0155, -0.0121,  0.0026, -0.0155, -0.0155, -0.0155, -0.0155, -0.0155,\n",
      "        -0.0155, -0.0155,  0.1620, -0.0155, -0.0155, -0.0155, -0.0176, -0.0155],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0055, -0.0153,  0.0146,  0.0045, -0.0138, -0.0153, -0.0153, -0.0173,\n",
      "        -0.0462, -0.0153,  0.0178,  0.0047,  0.1018, -0.0153,  0.0112, -0.0153],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0049, -0.0152, -0.0152, -0.0152, -0.0066,  0.0018, -0.0152,  0.0601,\n",
      "        -0.0152, -0.0152, -0.0152, -0.0152,  0.0044,  0.1361, -0.0152, -0.0152],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0151, -0.0151, -0.0151, -0.0151, -0.0150, -0.0151, -0.0151,  0.0422,\n",
      "        -0.0151, -0.0151, -0.0151,  0.0384, -0.0151, -0.0151,  0.0729, -0.0151],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0150, -0.0141, -0.0150, -0.0150, -0.0151, -0.0150, -0.0150,  0.0036,\n",
      "         0.0254, -0.0150, -0.0150,  0.0190, -0.0150, -0.0150, -0.0150, -0.0134],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0148, -0.0148, -0.0148], grad_fn=<SqueezeBackward1>)\n",
      "Epoch 10/20  Train: 1.325226e-03  Val: 9.736246e-04  Test: 4.522098e-04 ← best\n",
      "tensor([-0.0147, -0.0129,  0.0078, -0.0147, -0.0147, -0.0147,  0.0625, -0.0147,\n",
      "        -0.0147, -0.0147,  0.0209, -0.0147, -0.0147, -0.0147,  0.0034, -0.0147],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0146,  0.0035, -0.0146, -0.0146, -0.0155, -0.0146, -0.0146, -0.0146,\n",
      "        -0.0145, -0.0146,  0.0011,  0.0121, -0.0006, -0.0146, -0.0142, -0.0146],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0145, -0.0145, -0.0145,  0.0040, -0.0145, -0.0145, -0.0145, -0.0140,\n",
      "        -0.0145, -0.0162, -0.0145, -0.0145, -0.0145, -0.0206,  0.0176, -0.0145],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0138,  0.0029, -0.0143, -0.0332, -0.0143, -0.0046, -0.0143, -0.0143,\n",
      "         0.0025, -0.0151, -0.0143, -0.0153, -0.0143, -0.0143, -0.0143,  0.3030],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0141, -0.0119, -0.0141, -0.0141,  0.0885, -0.0141, -0.0141,  0.0057,\n",
      "        -0.0141, -0.0189,  0.1032, -0.0232, -0.0141, -0.0141, -0.0141, -0.0141],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0306, -0.0140, -0.0140, -0.0140,  0.0519, -0.0140, -0.0140, -0.0140,\n",
      "        -0.1113,  0.0040, -0.0140, -0.0140, -0.0140, -0.0140,  0.0919, -0.0579],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0139,  0.0128,  0.0026, -0.0135, -0.0139,  0.0574, -0.0139, -0.0080,\n",
      "        -0.0139, -0.0139, -0.0139, -0.0177, -0.0124,  0.0308, -0.0139,  0.0603],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0137, -0.0137, -0.0137, -0.0148,  0.0205, -0.0045,  0.0334,  0.0157,\n",
      "         0.0011, -0.0137, -0.0137, -0.0137, -0.0137, -0.0137, -0.0137, -0.0137],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0136, -0.0136,  0.0057, -0.0136, -0.0136,  0.0195, -0.0136, -0.0136,\n",
      "        -0.0136, -0.0136, -0.0136, -0.0136, -0.0136, -0.0136, -0.0136, -0.0136],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0134,  0.0192, -0.0134, -0.0134,  0.0123, -0.0053, -0.0134, -0.0063,\n",
      "        -0.0134, -0.0134, -0.0190, -0.0134, -0.0134, -0.0134, -0.0239, -0.0134],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0132, -0.0134, -0.0073, -0.0132, -0.0058, -0.0320, -0.0132,  0.0033,\n",
      "        -0.0132,  0.0010, -0.0295, -0.0107, -0.0410, -0.0132, -0.0132,  0.0048],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0131, -0.0131, -0.0131, -0.0131,  0.3343, -0.0131, -0.0131, -0.0171,\n",
      "        -0.0131, -0.0057, -0.0131, -0.0131, -0.0131, -0.0131, -0.0148, -0.0131],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0129, -0.0129,  0.0310, -0.0129, -0.0105, -0.0129, -0.0081,  0.0013,\n",
      "        -0.0129,  0.0257, -0.0129,  0.0231, -0.0129, -0.0129, -0.0129,  0.0113],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0200, -0.0128, -0.0128,  0.0050, -0.0128, -0.0128, -0.0128, -0.0128,\n",
      "        -0.0005,  0.0097, -0.0047, -0.0128, -0.0128,  0.0329, -0.0129, -0.0128],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0127, -0.0127, -0.3050, -0.0127,  0.0632,  0.0132, -0.0127,  0.0303,\n",
      "         0.0163,  0.0280, -0.0127, -0.0127, -0.0127, -0.0127, -0.0127, -0.0127],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0769, -0.0125,  0.0530, -0.1550,  0.0083, -0.0125, -0.0125,  0.0080,\n",
      "         0.0073, -0.0125, -0.0043, -0.0125, -0.0125, -0.0125, -0.0125, -0.0125],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0123,  0.0101, -0.0123, -0.0123, -0.0117, -0.0123, -0.0123, -0.0123,\n",
      "         0.0434,  0.0219, -0.0123, -0.0072, -0.0123,  0.0042, -0.0123, -0.0161],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0121,  0.0165, -0.0048,  0.0522, -0.0121,  0.0289, -0.0121, -0.0121,\n",
      "        -0.0121,  0.0023, -0.0121, -0.0121,  0.0269,  0.0102, -0.0806, -0.0199],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0119, -0.0455,  0.0130, -0.0013, -0.0119, -0.0119,  0.0462, -0.0119,\n",
      "        -0.0119,  0.2483,  0.0108, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0118, -0.0075, -0.0002, -0.0118, -0.0118, -0.0050, -0.0118, -0.0118,\n",
      "        -0.0096, -0.0118, -0.0118, -0.0029, -0.0310, -0.0118, -0.0118, -0.0118],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0060,  0.0159, -0.0138, -0.0117, -0.0117, -0.0117, -0.0249, -0.0117,\n",
      "        -0.0037, -0.0117,  0.0361, -0.0117, -0.0028,  0.0022,  0.0065, -0.0117],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0115,  0.0271, -0.0115, -0.0115, -0.0115, -0.0010, -0.0063, -0.0115,\n",
      "        -0.0206, -0.0115, -0.0115, -0.0115,  0.0962, -0.0362, -0.0115, -0.0270],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0113, -0.0113, -0.0113, -0.0113, -0.0113, -0.0113, -0.0113, -0.1815,\n",
      "        -0.0024, -0.0113, -0.0113, -0.0144, -0.0113, -0.0113, -0.0113,  0.0836],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0112, -0.0018, -0.0112, -0.0112, -0.0171, -0.0112, -0.0032,  0.0040,\n",
      "        -0.0112,  0.0597, -0.0112, -0.0112, -0.0078, -0.0112, -0.0382,  0.0094],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0083, -0.0110,  0.0296, -0.0011, -0.0175,  0.0010,  0.1063, -0.0110,\n",
      "        -0.0110, -0.0110,  0.0008,  0.0052,  0.0112, -0.0110, -0.0110, -0.0110],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0108, -0.0108,  0.0205,  0.0009, -0.0108, -0.0108, -0.0108,  0.0033,\n",
      "        -0.0108, -0.0105, -0.0108, -0.0108, -0.0108, -0.0033, -0.0108, -0.0108],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0107, -0.0107, -0.0546,  0.0059, -0.0107, -0.0107, -0.0107,  0.0199,\n",
      "        -0.0085, -0.0107,  0.0115, -0.0107, -0.0040,  0.0781,  0.0260,  0.0293],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0106,  0.0191, -0.0106, -0.0106, -0.0040, -0.0106,  0.0268, -0.0106,\n",
      "        -0.0106,  0.0112, -0.0029, -0.0106, -0.0106, -0.0106, -0.0106,  0.0108],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0105, -0.0105,  0.0107], grad_fn=<SqueezeBackward1>)\n",
      "Epoch 11/20  Train: 1.786900e-03  Val: 7.815085e-04  Test: 3.510897e-04 ← best\n",
      "tensor([-0.0104, -0.0104, -0.0104, -0.0104, -0.0104, -0.0021, -0.0104,  0.0024,\n",
      "        -0.0025, -0.0104, -0.0104, -0.0104, -0.0104, -0.0104,  0.0001, -0.0974],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.1082,  0.0283, -0.0103, -0.0103, -0.0295, -0.0103, -0.0103, -0.0103,\n",
      "        -0.0103,  0.0250, -0.0103, -0.0103,  0.0066, -0.0103, -0.0103, -0.0103],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0101, -0.0101, -0.0101, -0.0064,  0.0807, -0.0120, -0.0061,  0.0198,\n",
      "        -0.0101,  0.0873, -0.0101, -0.0101, -0.0101, -0.0101, -0.0940, -0.0101],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0423,  0.0142,  0.0084, -0.0100, -0.0060, -0.0100, -0.0100, -0.0100,\n",
      "        -0.0100, -0.0100, -0.0100,  0.0804, -0.0100, -0.0100,  0.0166,  0.0365],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0100, -0.0100, -0.0100, -0.0100,  0.1356, -0.0100, -0.0100, -0.1535,\n",
      "        -0.0100, -0.0002, -0.0100, -0.0100, -0.0100, -0.0100,  0.0011,  0.0533],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0099, -0.0099, -0.0099, -0.0099,  0.1020, -0.0082, -0.0005, -0.0099,\n",
      "        -0.0043, -0.0198, -0.0099, -0.0044, -0.0099, -0.0099,  0.0057, -0.0099],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0222, -0.0098, -0.0098, -0.0071, -0.0098, -0.0098, -0.0098, -0.0062,\n",
      "         0.0212, -0.0098,  0.0121, -0.0098, -0.0546, -0.0098, -0.0098,  0.0502],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0098, -0.0079,  0.0029, -0.0082, -0.0098, -0.0098,  0.0485, -0.0098,\n",
      "        -0.0098,  0.0076,  0.0095, -0.0098,  0.0008, -0.0098, -0.0098, -0.0100],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0097, -0.0097,  0.0146,  0.0038,  0.0033,  0.0207, -0.0097, -0.0097,\n",
      "        -0.0017, -0.0097, -0.0097,  0.0145, -0.0097, -0.0097, -0.0033,  0.0499],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0096, -0.0113,  0.2070, -0.0096, -0.0096, -0.0096, -0.0096, -0.0127,\n",
      "        -0.0096, -0.0134, -0.0096,  0.0482, -0.0096, -0.0096, -0.0096, -0.0096],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0096, -0.0096, -0.0096, -0.0096, -0.0096, -0.0096,  0.0859,  0.0162,\n",
      "         0.0053, -0.0096, -0.0096,  0.0028,  0.2378, -0.0066, -0.0078,  0.0240],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0054,  0.0260, -0.0096, -0.0096,  0.0236, -0.0085,  0.0010, -0.0096,\n",
      "        -0.0096,  0.0140, -0.0096, -0.0096, -0.0096, -0.0096,  0.0178, -0.0096],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0096,  0.0287,  0.0172, -0.0096, -0.0073,  0.0118, -0.0096, -0.0096,\n",
      "        -0.0096, -0.0096,  0.0070, -0.0096,  0.0198, -0.0096, -0.0096, -0.0065],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0096, -0.0096, -0.0096, -0.0096,  0.0205,  0.0066, -0.0096, -0.0096,\n",
      "         0.0419, -0.0096, -0.0096,  0.0149, -0.0096, -0.0096, -0.0096,  0.0723],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0343, -0.0097, -0.0095, -0.0097, -0.0097, -0.0097, -0.0097, -0.0097,\n",
      "         0.1392, -0.0097, -0.0097, -0.0097, -0.0097, -0.0097,  0.0161, -0.0097],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0097,  0.0087,  0.0214, -0.0097, -0.0037, -0.0097, -0.0541,  0.0061,\n",
      "        -0.0097, -0.0097, -0.0097, -0.0097,  0.0131,  0.0214, -0.0117, -0.0097],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0097, -0.0097, -0.0132, -0.0097, -0.0097, -0.0097, -0.0097, -0.0097,\n",
      "         0.0327, -0.0097,  0.0145, -0.0097,  0.0558,  0.0094,  0.0036, -0.0097],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0097, -0.0097, -0.0287, -0.0097, -0.0097, -0.0041, -0.0121,  0.0373,\n",
      "        -0.0097, -0.0097, -0.0003, -0.0097, -0.0048, -0.0097, -0.0097, -0.0097],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0096, -0.0089, -0.0096,  0.0713, -0.0096, -0.0096, -0.0263, -0.0096,\n",
      "        -0.0096, -0.0096,  0.0011,  0.0047, -0.0096, -0.0096, -0.0357, -0.0115],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0096,  0.0584, -0.0081, -0.0096, -0.0096, -0.0096,  0.0159, -0.0096,\n",
      "         0.0153, -0.0052, -0.0176, -0.0096, -0.0096, -0.0120, -0.0096, -0.0096],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0095, -0.0036,  0.0044, -0.0095, -0.0095, -0.0095, -0.0014, -0.0095,\n",
      "        -0.0095, -0.0095,  0.0083, -0.0116, -0.0095, -0.0095, -0.0095,  0.0072],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0204, -0.0094,  0.0153, -0.0094, -0.0094, -0.0094, -0.0094, -0.0156,\n",
      "         0.0384, -0.0429, -0.0094, -0.0094, -0.0878, -0.0094, -0.0094, -0.0094],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0092,  0.0115,  0.0168,  0.0314, -0.0038, -0.0092, -0.0092,  0.0025,\n",
      "         0.0178,  0.0403, -0.0094, -0.0092, -0.0092, -0.0092, -0.0092, -0.0221],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0089,  0.0196,  0.0628,  0.0081, -0.0083, -0.0061, -0.0091, -0.0110,\n",
      "        -0.0091, -0.0091, -0.0091, -0.0091, -0.0091,  0.0261, -0.0091,  0.0095],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0090, -0.0091, -0.0090, -0.0090, -0.0090,  0.0185, -0.0090, -0.0090,\n",
      "         0.0461, -0.0090, -0.0090,  0.0305, -0.0090, -0.0090, -0.0090, -0.0090],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0089,  0.0137, -0.0089, -0.0089, -0.0089, -0.0089, -0.0089,  0.0213,\n",
      "         0.0035, -0.0089, -0.0089, -0.0044, -0.0089, -0.0089, -0.0089, -0.0089],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0472, -0.0134, -0.0088, -0.0227, -0.0088,  0.0838, -0.0006,  0.0113,\n",
      "        -0.0088, -0.0088, -0.0088,  0.0013, -0.0029, -0.0094, -0.0088, -0.0088],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0293, -0.0088, -0.0088,  0.0024, -0.0088, -0.0088, -0.0088, -0.0088,\n",
      "        -0.0088,  0.0789, -0.0088, -0.0088, -0.0088, -0.0088,  0.0130, -0.0088],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0087, -0.0087,  0.0822], grad_fn=<SqueezeBackward1>)\n",
      "Epoch 12/20  Train: 1.103316e-03  Val: 6.010962e-04  Test: 3.245742e-04 ← best\n",
      "tensor([-0.0087, -0.0087, -0.0160, -0.0087, -0.1734, -0.0087, -0.0161,  0.0188,\n",
      "        -0.0081, -0.0087, -0.0097,  0.0278, -0.0087, -0.0087, -0.0087, -0.0087],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0087, -0.0071,  0.0484, -0.0087, -0.0087, -0.0087,  0.0391, -0.0087,\n",
      "        -0.0087, -0.0087, -0.0087, -0.0087, -0.0087, -0.0087, -0.0087, -0.0078],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0086, -0.0090, -0.0086, -0.0109, -0.0086,  0.0415, -0.0114, -0.0086,\n",
      "        -0.0086,  0.0111,  0.0066, -0.0086, -0.0086, -0.0086, -0.0086,  0.1648],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0086, -0.0086, -0.0108, -0.0086, -0.0086, -0.0086, -0.0063, -0.0086,\n",
      "        -0.0086, -0.0086, -0.0086, -0.0086, -0.0086, -0.0086,  0.0283, -0.0086],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0085, -0.0085, -0.0085, -0.0085,  0.0345, -0.0085, -0.0085, -0.0085,\n",
      "        -0.0085, -0.0085, -0.0085,  0.0263, -0.0085, -0.0085, -0.0074, -0.0085],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0085, -0.0076, -0.0361, -0.0085,  0.0303, -0.0085, -0.0085,  0.0022,\n",
      "        -0.0085, -0.0085,  0.0151, -0.0085, -0.0085, -0.0023, -0.0085, -0.0085],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0116, -0.0084,  0.0163, -0.0076, -0.0084,  0.0038, -0.0060, -0.0084,\n",
      "        -0.0084, -0.0084, -0.0084, -0.0234,  0.1042, -0.0084, -0.0084, -0.0084],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0083, -0.0083, -0.0083,  0.0487, -0.0083, -0.0083, -0.0025, -0.0110,\n",
      "        -0.0083, -0.0083, -0.0083,  0.0072, -0.0083,  0.0056, -0.0083, -0.0083],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0082,  0.0190, -0.0082, -0.0082, -0.0071, -0.0082, -0.0082, -0.0082,\n",
      "        -0.0082,  0.0181, -0.0082, -0.0082, -0.0082, -0.0082, -0.0082,  0.0129],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-8.2041e-03,  2.3136e-02, -9.8937e-05,  8.4795e-02, -9.6983e-03,\n",
      "        -8.2041e-03, -8.2041e-03, -1.1212e-02,  4.1351e-03, -8.2041e-03,\n",
      "        -2.4571e-02, -8.2041e-03, -8.2041e-03, -8.2041e-03, -8.2041e-03,\n",
      "         5.7622e-03], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0010,  0.0111, -0.0082, -0.0082, -0.0322, -0.0082, -0.0082, -0.0013,\n",
      "         0.0147, -0.0082, -0.0082,  0.0136, -0.0082, -0.0082, -0.0286, -0.0030],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 7.0746e-05,  8.7637e-03, -8.1228e-03, -8.1228e-03, -8.1228e-03,\n",
      "        -8.1228e-03, -8.1228e-03,  1.1382e-01, -8.1228e-03,  2.4738e-02,\n",
      "        -8.1228e-03, -8.1228e-03,  1.4981e-02, -8.1228e-03, -8.1228e-03,\n",
      "        -8.1228e-03], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0081, -0.0081, -0.0081, -0.0081, -0.0081, -0.0081, -0.0081,  0.0856,\n",
      "         0.0001, -0.0081, -0.0081, -0.0081, -0.0081, -0.0081, -0.0081,  0.0928],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0080,  0.0059, -0.0080, -0.0080, -0.0080, -0.0080, -0.0080, -0.0080,\n",
      "         0.0218,  0.0035, -0.0080,  0.0027, -0.0080, -0.0080, -0.0080, -0.0080],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0682,  0.0287,  0.0062, -0.0080,  0.0053, -0.0080, -0.0080, -0.0080,\n",
      "         0.0181, -0.0080, -0.0135,  0.0079,  0.0667, -0.0080,  0.0138, -0.0080],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0079, -0.0129, -0.0079, -0.0079,  0.0660, -0.0079, -0.0079,  0.0520,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0008, -0.0079],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,  0.2568, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079,  0.0020, -0.0022,  0.0010, -0.0079],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0036, -0.0080, -0.0080, -0.0080, -0.0091, -0.0080, -0.0080, -0.0080,\n",
      "         0.0233, -0.0080, -0.0012, -0.0080, -0.0799, -0.0080, -0.0080, -0.0080],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0211, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0545, -0.0079, -0.0079, -0.0079, -0.0468],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0079, -0.0079, -0.0079,  0.0352,  0.0027, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0081, -0.0360, -0.0055, -0.0079, -0.0079, -0.0079, -0.0079],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0079, -0.0109, -0.0079, -0.0116, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "         0.0654, -0.0079, -0.0079, -0.0079, -0.0079,  0.0194, -0.0079, -0.0148],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.1816,  0.0083,  0.0002, -0.0078, -0.0196, -0.0078, -0.0195, -0.0078,\n",
      "        -0.0108,  0.0171, -0.0078, -0.0078, -0.0078,  0.0122,  0.0105, -0.0078],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0280, -0.0077, -0.0077, -0.0077, -0.0077, -0.0077, -0.0077, -0.0077,\n",
      "        -0.0077, -0.0077, -0.0077, -0.0077, -0.0077, -0.0077, -0.0077, -0.0250],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0027, -0.0076, -0.0076, -0.0076, -0.0076, -0.0237, -0.0076, -0.0076,\n",
      "         0.0449, -0.0076,  0.0071, -0.0060, -0.0076, -0.0076, -0.0076, -0.0076],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0036,  0.0047, -0.0074, -0.0074, -0.0074, -0.0043, -0.0003,  0.1667,\n",
      "        -0.0074, -0.0074, -0.0074, -0.0074, -0.0108, -0.0074, -0.0074, -0.0074],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0073, -0.0073, -0.0073, -0.0073,  0.0166, -0.0073, -0.0073, -0.0073,\n",
      "        -0.0073, -0.0073, -0.0073, -0.0073,  0.0017, -0.0073, -0.0073, -0.0073],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0072, -0.0072, -0.0072,  0.0222, -0.0072, -0.0072, -0.0072, -0.0072,\n",
      "        -0.0072, -0.0072, -0.0072, -0.0072, -0.0072, -0.0139, -0.0072, -0.0163],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0071,  0.0025,  0.0059,  0.0332, -0.0071, -0.0071, -0.0071, -0.0071,\n",
      "        -0.0071, -0.0071, -0.0071, -0.0071, -0.0071,  0.0008,  0.0540,  0.0229],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0070, -0.0070, -0.0022], grad_fn=<SqueezeBackward1>)\n",
      "Epoch 13/20  Train: 9.106025e-04  Val: 4.885372e-04  Test: 2.986743e-04 ← best\n",
      "tensor([ 0.0328, -0.0069, -0.0069, -0.0107,  0.0018, -0.0069, -0.0069, -0.0069,\n",
      "        -0.0014, -0.0069, -0.0069, -0.0069, -0.0069, -0.0069, -0.0818, -0.0069],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0067, -0.0067,  0.0020, -0.0067, -0.0067, -0.0067, -0.0147, -0.0020,\n",
      "        -0.0067, -0.0067, -0.0067, -0.0067, -0.0277,  0.0065, -0.0067, -0.0067],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0066,  0.0178, -0.0040, -0.0066, -0.0112, -0.0066,  0.0059, -0.0066,\n",
      "        -0.0066, -0.2279, -0.0066, -0.0066, -0.0066, -0.0066, -0.0066,  0.0059],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0064, -0.0064,  0.0271,  0.0151, -0.0064,  0.0451, -0.0064, -0.0186,\n",
      "         0.0318, -0.0064,  0.0011, -0.0064, -0.0039,  0.0097, -0.0494,  0.0138],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0062, -0.0124, -0.0062, -0.0062, -0.0062, -0.0062, -0.0062, -0.0062,\n",
      "        -0.0062, -0.0062,  0.0561, -0.0062, -0.0020, -0.0062, -0.0062, -0.0062],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0281, -0.0060, -0.0060,  0.0103, -0.0060, -0.0060,  0.0159, -0.0060,\n",
      "        -0.0060, -0.0060, -0.0060, -0.0060, -0.0060, -0.0128, -0.0009, -0.0060],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0058, -0.0058, -0.0058,  0.0099, -0.0069, -0.0058, -0.0058, -0.0058,\n",
      "         0.0060, -0.0058, -0.0058,  0.0135, -0.0058, -0.0246, -0.0090, -0.0058],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0056, -0.0018, -0.0056, -0.0056, -0.0056,  0.0229, -0.0026, -0.0056,\n",
      "        -0.0056, -0.0056, -0.0056, -0.0003, -0.0056, -0.0056,  0.0547, -0.0056],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0010, -0.0055, -0.0055,  0.0030, -0.0055, -0.0006, -0.0055, -0.0055,\n",
      "        -0.0055, -0.0055, -0.0176, -0.0055, -0.0055, -0.0055, -0.0055, -0.0055],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0053, -0.0692, -0.0053, -0.0053,  0.0898, -0.0053, -0.0053, -0.0053,\n",
      "        -0.0083, -0.0053, -0.0053, -0.0053, -0.0053, -0.0053, -0.0053, -0.0053],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0052, -0.0041, -0.0052, -0.0052, -0.0052,  0.0186, -0.0052, -0.0052,\n",
      "         0.0214, -0.0052, -0.0052, -0.0052, -0.0052, -0.0052, -0.0052, -0.0115],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0051, -0.0590, -0.0051,  0.0682,  0.0100, -0.0051, -0.0051, -0.0051,\n",
      "        -0.0066,  0.0252, -0.0051, -0.0051, -0.0051, -0.0051, -0.0005,  0.0009],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0008,  0.0099, -0.0049, -0.0049,  0.0122, -0.0034, -0.0049,  0.0092,\n",
      "        -0.0050, -0.0115, -0.0049, -0.0049, -0.0049, -0.0049,  0.0098,  0.0013],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0048,  0.0382, -0.0048,  0.0042, -0.0048, -0.0048, -0.0048, -0.0048,\n",
      "        -0.0048, -0.0048, -0.0048, -0.0219, -0.0048, -0.0048, -0.0048, -0.0048],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0047,  0.0145, -0.0019, -0.0047, -0.0047,  0.0003, -0.1923, -0.0080,\n",
      "         0.0066, -0.0047, -0.0047,  0.0185, -0.0047, -0.0047, -0.0047,  0.0162],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0046, -0.0046,  0.0309, -0.0046, -0.0046,  0.0441,  0.0093,  0.0027,\n",
      "        -0.0046, -0.0046, -0.0046, -0.0046,  0.0085, -0.0021, -0.0046, -0.0046],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0122, -0.0045, -0.0045, -0.0045, -0.0045, -0.0045,  0.0180, -0.0045,\n",
      "        -0.0045, -0.0045, -0.0045, -0.0045, -0.0045,  0.0112, -0.0045,  0.0381],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0044,  0.0025, -0.0044, -0.0044,  0.0062,  0.0067, -0.0044,  0.0015,\n",
      "        -0.0044, -0.0044, -0.0044, -0.0044, -0.0044, -0.0044, -0.0044, -0.0997],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0043,  0.0113, -0.0043, -0.0043, -0.0043, -0.0043, -0.0043, -0.0043,\n",
      "        -0.0043, -0.0043,  0.0257, -0.0043, -0.0677, -0.0043,  0.0023, -0.0040],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0042, -0.0042, -0.0042, -0.0042, -0.0042, -0.0042, -0.0042, -0.0042,\n",
      "        -0.0031,  0.0151, -0.0042, -0.0042, -0.0042, -0.0042, -0.0042, -0.0042],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0019, -0.0041, -0.0041, -0.0041, -0.0041, -0.0059, -0.0417, -0.0041,\n",
      "        -0.0041, -0.0041, -0.0115, -0.0041,  0.0265, -0.0041, -0.0080, -0.0041],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0004, -0.0040, -0.0040, -0.0040, -0.0040, -0.0040, -0.0050,  0.0139,\n",
      "         0.0051, -0.0040, -0.0040, -0.0040, -0.0032, -0.0040,  0.0018,  0.0012],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0090,  0.0181, -0.0039,  0.0649, -0.0039, -0.0039,  0.0795, -0.0039,\n",
      "        -0.0044, -0.0039, -0.0039, -0.0039, -0.0039, -0.0039, -0.0039, -0.0039],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0038, -0.0038, -0.0038,  0.0021, -0.0028, -0.0038, -0.0038, -0.0038,\n",
      "        -0.0038, -0.0038, -0.0053, -0.0038,  0.0387, -0.0038, -0.0038, -0.0038],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0037, -0.0037, -0.0037, -0.0299, -0.0037,  0.0037, -0.0037, -0.0037,\n",
      "        -0.0037, -0.0037, -0.0037, -0.0037, -0.0037, -0.0208, -0.0365, -0.0037],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0039, -0.0036, -0.0036, -0.0452, -0.0036,  0.0549, -0.0082,  0.0432,\n",
      "        -0.0036, -0.0036, -0.0280, -0.0036,  0.0014, -0.0036, -0.0036, -0.0036],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0035, -0.0035, -0.0035, -0.0035, -0.0035, -0.0035, -0.0035, -0.0035,\n",
      "        -0.0035, -0.0023, -0.0035, -0.0012, -0.0062,  0.0093,  0.0079, -0.0035],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0033, -0.0034,  0.0251, -0.0034, -0.0034, -0.0034, -0.0038,  0.0013,\n",
      "        -0.0034, -0.0011,  0.0056, -0.0034, -0.0034, -0.0035, -0.0034, -0.0034],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0033, -0.0033, -0.0033], grad_fn=<SqueezeBackward1>)\n",
      "Epoch 14/20  Train: 6.804220e-04  Val: 4.115799e-04  Test: 2.632422e-04 ← best\n",
      "tensor([-0.0032,  0.0409, -0.0055, -0.0032,  0.0004,  0.0059,  0.0045, -0.0032,\n",
      "        -0.0012, -0.0032,  0.0342, -0.0032,  0.0054, -0.0032, -0.0032, -0.0032],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0030, -0.0030, -0.0030, -0.0030, -0.0030,  0.0653, -0.0030, -0.0030,\n",
      "        -0.0030,  0.0045, -0.0030, -0.0030, -0.0030,  0.0325, -0.0030, -0.0030],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0380, -0.0030, -0.0030, -0.0030, -0.0030, -0.0030, -0.0030, -0.0030,\n",
      "        -0.0030, -0.0030, -0.0030, -0.0030, -0.0030, -0.0030, -0.0030, -0.0010],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0029, -0.0029, -0.0029, -0.0029, -0.0029,  0.0470, -0.0029,  0.0001,\n",
      "        -0.0029, -0.0029, -0.0061, -0.0058, -0.0029, -0.0029, -0.0154, -0.0029],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0028,  0.0056, -0.0028, -0.0044, -0.0028, -0.0028, -0.0038, -0.0084,\n",
      "        -0.0028, -0.0028, -0.0028,  0.0606, -0.0028, -0.0028, -0.0028, -0.0028],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0028, -0.0028, -0.0028, -0.0028, -0.0028,  0.0327, -0.0028, -0.0028,\n",
      "        -0.0028,  0.0049, -0.0091, -0.0028, -0.0028, -0.0233, -0.0028, -0.0028],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0027, -0.0025,  0.0351,  0.0483, -0.0027, -0.0055, -0.0027, -0.0027,\n",
      "        -0.0027, -0.0027,  0.0037, -0.0027, -0.0010, -0.0027, -0.0031, -0.0050],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0026, -0.0026, -0.0026, -0.0024, -0.0026, -0.0026, -0.0018, -0.0026,\n",
      "        -0.0026, -0.0026,  0.0038, -0.0211, -0.0026, -0.0026, -0.0026, -0.0026],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-2.3461e-03,  1.6186e-02, -2.5925e-03, -2.5925e-03,  7.3328e-02,\n",
      "        -2.5925e-03, -2.5925e-03,  1.1950e-02, -2.5925e-03,  1.7119e-02,\n",
      "        -1.0379e-04, -1.4890e-01, -2.5925e-03,  3.7617e-02, -1.0987e-02,\n",
      "         5.9566e-03], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0034, -0.0026, -0.0870, -0.0026,  0.0112, -0.0112, -0.0026, -0.0026,\n",
      "        -0.0026,  0.0145, -0.0026, -0.0026, -0.0026, -0.0026, -0.0026, -0.0026],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0025, -0.0025, -0.0025, -0.0025, -0.0025, -0.0025,  0.0056,  0.0113,\n",
      "         0.0029, -0.0032, -0.0025, -0.0025, -0.0026, -0.0025, -0.0025, -0.0025],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0025, -0.0025, -0.0025, -0.0025, -0.0025,  0.0033, -0.0025, -0.0025,\n",
      "        -0.0025, -0.0025,  0.0214, -0.0025, -0.0025, -0.0025,  0.0068, -0.0025],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0259, -0.0025, -0.0025, -0.0025, -0.1120, -0.0025,  0.0091, -0.0025,\n",
      "        -0.0025, -0.0572, -0.0025, -0.0025,  0.0092, -0.0025, -0.0025,  0.0202],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0081, -0.0028, -0.0024,  0.0318,  0.0234,  0.0057,  0.0026, -0.0024,\n",
      "        -0.0024, -0.0024, -0.0024, -0.0024,  0.0550, -0.0069, -0.0024, -0.0024],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0023,  0.0267,  0.0029, -0.0023, -0.0023, -0.0009, -0.0023, -0.0023,\n",
      "        -0.0023, -0.0023, -0.0023, -0.0023, -0.0023, -0.0023, -0.0023, -0.0023],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0023, -0.0027, -0.0023, -0.0023,  0.0156,  0.0002, -0.0023, -0.0023,\n",
      "        -0.0023, -0.0023, -0.0023, -0.0023,  0.1126, -0.0023,  0.0083,  0.0009],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0022, -0.0022, -0.0075,  0.1704, -0.0022, -0.0022,  0.0006, -0.0022,\n",
      "        -0.0022,  0.0223,  0.0034,  0.0092, -0.0002, -0.0069,  0.0326, -0.0022],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
      "        -0.0022, -0.0022, -0.0022, -0.0018, -0.0022, -0.0022, -0.0041, -0.0022],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0022, -0.0022, -0.0022,  0.0263, -0.0022, -0.0022, -0.0022,  0.0046,\n",
      "        -0.0022, -0.0022,  0.0219, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0022,  0.0083, -0.0022, -0.0022, -0.0047, -0.0022, -0.0022, -0.0022,\n",
      "        -0.0022,  0.0035, -0.0022, -0.0022, -0.0022,  0.0187, -0.0022, -0.0022],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0018, -0.0022,\n",
      "        -0.0022, -0.0022,  0.0476, -0.0022, -0.0022, -0.0022, -0.0022,  0.0225],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0022, -0.0022, -0.0022, -0.0022, -0.0022,  0.0012, -0.0022, -0.0022,\n",
      "         0.0351, -0.0022,  0.0055, -0.0022, -0.0022, -0.0016, -0.0100, -0.0022],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0022, -0.0022, -0.0022, -0.0022,  0.0021, -0.0074, -0.0088,  0.0201,\n",
      "         0.0214, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0022, -0.0022,  0.0088, -0.0022, -0.0022,  0.0042, -0.0022, -0.0708,\n",
      "        -0.0022, -0.0022, -0.0022, -0.0022, -0.0037, -0.0022, -0.0022, -0.0022],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0022, -0.0022, -0.0022,  0.0037, -0.0022, -0.0022,  0.0087,  0.0060,\n",
      "         0.0377, -0.0022, -0.0022, -0.0022, -0.0088, -0.0022, -0.0022, -0.0043],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0123, -0.0021, -0.0021, -0.0021, -0.0021, -0.0021,  0.0153,  0.0129,\n",
      "         0.0146, -0.0021, -0.0021, -0.0021, -0.0021, -0.0021, -0.0021, -0.0021],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0021, -0.0021, -0.0620, -0.0021, -0.0021,  0.1089, -0.0021, -0.0019,\n",
      "        -0.0021, -0.0021, -0.0021, -0.0342,  0.0088, -0.0021, -0.0018,  0.0034],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0090, -0.0020, -0.0014,  0.0305,  0.0041,  0.0142, -0.0020, -0.0020,\n",
      "         0.0183,  0.0015, -0.0115, -0.0020, -0.0020, -0.0020,  0.0010, -0.0020],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0020, -0.0020, -0.0017], grad_fn=<SqueezeBackward1>)\n",
      "Epoch 15/20  Train: 6.575838e-04  Val: 3.565327e-04  Test: 2.588961e-04 ← best\n",
      "tensor([-0.0020,  0.0434, -0.0020, -0.0020, -0.0020, -0.0020,  0.0037, -0.0020,\n",
      "         0.1080, -0.0108,  0.0386, -0.0020,  0.0111, -0.0020,  0.0125, -0.0020],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0742, -0.0020, -0.0020, -0.0020, -0.0020,  0.0105,  0.0187,  0.0202,\n",
      "        -0.0020,  0.2448,  0.0168, -0.0020, -0.0020, -0.0020, -0.0013, -0.0020],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0020, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020,\n",
      "        -0.0020, -0.0020,  0.0062, -0.0020, -0.0020,  0.0016, -0.0020, -0.0020],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0021, -0.0021, -0.0020, -0.0093,  0.0211,  0.0162, -0.0021, -0.0021,\n",
      "        -0.0028, -0.0021, -0.0021,  0.0071,  0.0799, -0.0282,  0.0001, -0.0021],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0046, -0.0021, -0.0127,  0.0021, -0.0046, -0.0012, -0.0021, -0.0021,\n",
      "        -0.0021, -0.0021, -0.0041, -0.0021, -0.0021,  0.1716, -0.0021, -0.0021],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0022, -0.0022,  0.0106, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,\n",
      "         0.0236, -0.0022, -0.0022, -0.0022, -0.0030, -0.0022, -0.0022,  0.0113],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0022, -0.0022,  0.0213, -0.0022, -0.0022, -0.0022, -0.0022,  0.0213,\n",
      "        -0.0022, -0.0022,  0.0191,  0.0099, -0.0567, -0.0022, -0.0022, -0.0022],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0046, -0.0022, -0.0022, -0.0123, -0.0022, -0.0022, -0.0022, -0.0022,\n",
      "        -0.0022, -0.0022, -0.0088, -0.0022, -0.0022,  0.0062, -0.0022, -0.0022],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0113, -0.0022, -0.0022, -0.0022,  0.0019, -0.0022, -0.0022, -0.0022,\n",
      "        -0.0081, -0.0022,  0.0041, -0.0022,  0.1597, -0.0022, -0.0022, -0.0022],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0116, -0.0023, -0.0023, -0.0023, -0.0018, -0.0023, -0.0023, -0.0023,\n",
      "        -0.0023, -0.0023, -0.0023, -0.0646,  0.0487, -0.0023, -0.0023, -0.0023],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0023, -0.0023, -0.0023, -0.0023,  0.0096, -0.0018,  0.0433, -0.0023,\n",
      "        -0.0023, -0.0023, -0.0023, -0.0023, -0.0023, -0.0023, -0.0023, -0.0023],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0068, -0.0024, -0.0024, -0.0024, -0.0024, -0.0024, -0.0024, -0.0024,\n",
      "        -0.0024, -0.0024, -0.0024, -0.0024, -0.0024, -0.0024, -0.0024, -0.0024],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0024, -0.0024,  0.0047, -0.0024, -0.0024, -0.0024, -0.0024,  0.0008,\n",
      "        -0.0024, -0.0024, -0.0024, -0.0008, -0.0400, -0.0089, -0.0024, -0.0024],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0023, -0.0023, -0.0023, -0.0013, -0.0031, -0.0023, -0.0023, -0.0023,\n",
      "        -0.0023, -0.0023, -0.0023, -0.0023, -0.0204, -0.0023, -0.0023, -0.0023],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0023, -0.0023, -0.0023, -0.0124, -0.0023, -0.0186, -0.0004, -0.0023,\n",
      "        -0.0023, -0.0045, -0.0023, -0.0023,  0.0093,  0.0231, -0.0023,  0.0019],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0023, -0.0058, -0.0023, -0.0023,  0.0216, -0.0023, -0.0023, -0.0023,\n",
      "        -0.0023, -0.0023,  0.0007, -0.0023, -0.0023, -0.0283, -0.0023, -0.0040],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0024, -0.0024, -0.0024, -0.0024, -0.0024, -0.0024, -0.0024, -0.0024,\n",
      "        -0.0024, -0.0007,  0.0404, -0.0024,  0.0076, -0.0024, -0.0024, -0.0024],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0061, -0.0024, -0.0024, -0.0024, -0.0024, -0.0024, -0.0024, -0.0040,\n",
      "        -0.0024, -0.0021, -0.0024, -0.0024, -0.0024, -0.0024, -0.0024,  0.0787],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0002, -0.0014, -0.0024, -0.0024,  0.0915, -0.0024, -0.0024, -0.0024,\n",
      "        -0.0024,  0.0041, -0.0024, -0.0024, -0.0094, -0.0024, -0.0024, -0.0024],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0025, -0.0025, -0.0025, -0.0025, -0.0025,  0.0208,  0.0028,  0.0306,\n",
      "         0.0059, -0.0025, -0.0025, -0.0025, -0.0025,  0.0136, -0.0025, -0.0025],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0083, -0.0025, -0.0025, -0.0025, -0.0025, -0.0025, -0.0031, -0.0025,\n",
      "        -0.0025, -0.0025, -0.0025, -0.0025, -0.0025, -0.0025, -0.0025,  0.0172],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0025, -0.0025, -0.0025, -0.0025, -0.0025,  0.0177,  0.0331, -0.0025,\n",
      "        -0.0025, -0.0025, -0.0025, -0.0025, -0.0025, -0.0025, -0.0025,  0.0169],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0172, -0.0026, -0.0026,  0.0198,  0.0067, -0.0026, -0.0026, -0.0140,\n",
      "         0.0084, -0.0026, -0.0026, -0.0026, -0.0026,  0.0001, -0.0026, -0.0026],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0026, -0.0026,  0.0021,  0.0085, -0.0026, -0.0026, -0.0026, -0.0096,\n",
      "         0.0632, -0.0026,  0.0025, -0.0026, -0.0026, -0.0026, -0.0026, -0.0026],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0027, -0.0027, -0.0027, -0.0027, -0.0844, -0.0027, -0.0055, -0.0027,\n",
      "        -0.0027, -0.0027, -0.0027, -0.0027, -0.0027, -0.0027, -0.0195, -0.0027],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0027,  0.0081, -0.0027,  0.0120, -0.0404, -0.0027,  0.0159, -0.0027,\n",
      "        -0.0027, -0.0027, -0.0027, -0.0027, -0.0027, -0.0027, -0.0031, -0.0027],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0026, -0.0026, -0.0026, -0.0075, -0.0026, -0.0026, -0.0026,  0.0078,\n",
      "        -0.0026, -0.0026, -0.0026,  0.0165, -0.0026, -0.0015, -0.0026,  0.0091],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0026, -0.0026,  0.0059,  0.0078,  0.0171,  0.0358, -0.0026, -0.0026,\n",
      "         0.0051, -0.0026, -0.0026,  0.0221, -0.0026, -0.0026,  0.0033, -0.0026],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0026, -0.0098,  0.0074], grad_fn=<SqueezeBackward1>)\n",
      "Epoch 16/20  Train: 7.883783e-04  Val: 3.411854e-04  Test: 2.630967e-04 ← best\n",
      "tensor([-0.0025, -0.0025, -0.0025,  0.0041, -0.0025, -0.0025, -0.0025, -0.0025,\n",
      "        -0.0364, -0.0028,  0.1146, -0.0025, -0.0025, -0.0025, -0.0132, -0.0025],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-2.3861e-03, -2.3861e-03,  9.5884e-03, -3.5351e-02, -8.6802e-05,\n",
      "        -2.3861e-03, -2.3861e-03, -2.3861e-03, -2.3861e-03, -2.3861e-03,\n",
      "        -2.3861e-03, -2.3861e-03,  2.3927e-02, -2.3861e-03, -2.3861e-03,\n",
      "        -2.3861e-03], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0023, -0.0023, -0.0023, -0.0023, -0.0023, -0.0023,  0.0577, -0.0023,\n",
      "        -0.0023, -0.0023, -0.0023, -0.0023, -0.0023, -0.0023, -0.0023, -0.0023],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0022, -0.0022, -0.0022,  0.0021, -0.0022, -0.0022, -0.0022,  0.0185,\n",
      "        -0.0022, -0.0022, -0.0022, -0.0280, -0.0022, -0.0022, -0.0022, -0.0022],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0137, -0.0021,  0.0069, -0.0096, -0.0021, -0.0021, -0.0021,  0.0563,\n",
      "        -0.0021, -0.0021, -0.0021, -0.0021, -0.1227, -0.0021, -0.0021, -0.0021],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-2.0204e-03,  1.5210e-02, -2.0204e-03, -2.0204e-03,  1.1129e-01,\n",
      "         8.2110e-05, -8.6251e-03, -1.4736e-03, -2.0204e-03, -2.0204e-03,\n",
      "         4.6246e-03, -4.2237e-03, -2.0204e-03, -2.0204e-03, -2.0204e-03,\n",
      "        -2.0204e-03], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0019,  0.2503, -0.0084, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019,\n",
      "        -0.0019, -0.0019, -0.0299, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0055, -0.0019, -0.0019, -0.0019,  0.0140, -0.0019, -0.0019,  0.0357,\n",
      "        -0.0019, -0.0019,  0.0418, -0.0019, -0.0019, -0.0019, -0.0019, -0.0025],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0010, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019,\n",
      "        -0.0019, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019,  0.0105],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0019, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019, -0.0022, -0.0038,\n",
      "        -0.0019, -0.0019, -0.0019, -0.0019, -0.0019, -0.0024,  0.0063, -0.0019],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0055, -0.0018, -0.0018,  0.0028,  0.0036, -0.0172, -0.0018, -0.0018,\n",
      "        -0.0018, -0.0018,  0.0341, -0.0018,  0.0185, -0.0018, -0.0018,  0.0162],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0070, -0.0018, -0.0018, -0.0018, -0.0004, -0.0085, -0.0018, -0.0052,\n",
      "        -0.0018,  0.0074, -0.0018, -0.0018, -0.0018, -0.0018,  0.0018,  0.0111],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.1152,  0.0036, -0.0018, -0.0241, -0.0018,  0.0671, -0.0018, -0.0018,\n",
      "         0.0326, -0.0018, -0.0018, -0.0018,  0.0174, -0.0018, -0.0087, -0.0018],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0064, -0.0018, -0.0018, -0.0018, -0.0018, -0.0018, -0.0018, -0.0018,\n",
      "         0.1053, -0.0018, -0.0018, -0.0018, -0.0018, -0.0018, -0.0018, -0.0018],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0018, -0.0018, -0.0018, -0.0018, -0.0018, -0.0018, -0.0018, -0.0018,\n",
      "         0.0162, -0.0018, -0.0018, -0.0018, -0.0018, -0.0018,  0.0189, -0.0048],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0018, -0.0018, -0.0069, -0.0018, -0.0018,  0.0084,  0.0038,  0.0189,\n",
      "        -0.0011, -0.0018, -0.0018, -0.0018, -0.0018,  0.0029,  0.0046, -0.0018],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0018,  0.0105, -0.0018,  0.0012, -0.0018, -0.0018, -0.0018, -0.0018,\n",
      "        -0.0018, -0.0048, -0.0018, -0.0018, -0.0018, -0.0018, -0.0018, -0.0018],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0018,  0.0034, -0.0018, -0.0037,  0.0071, -0.0091, -0.0018, -0.0039,\n",
      "        -0.0018, -0.0004, -0.0018, -0.0018, -0.0018, -0.0018,  0.0273, -0.0018],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0066, -0.0018, -0.0049, -0.0018, -0.0018, -0.0004, -0.0018, -0.0018,\n",
      "        -0.0018, -0.0018,  0.0050, -0.0018,  0.0506, -0.0018, -0.0018,  0.0030],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0018, -0.0080, -0.0018, -0.0018, -0.0018, -0.0018,  0.0155, -0.0018,\n",
      "        -0.0018, -0.0077, -0.0018,  0.0065, -0.0018, -0.0018, -0.0018, -0.0018],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0021,  0.0124, -0.0018,  0.0253, -0.0018,  0.0109, -0.0018, -0.0018,\n",
      "        -0.0018, -0.0027, -0.0018,  0.0088, -0.0022, -0.0018, -0.0018, -0.0018],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0019, -0.0019, -0.0019,  0.0132, -0.0019, -0.0019, -0.0019, -0.0019,\n",
      "        -0.0019,  0.0276, -0.0019, -0.0019, -0.0019, -0.0019,  0.0019, -0.0019],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0019,  0.0037, -0.0019, -0.0019, -0.0012, -0.0019, -0.0019,  0.0014,\n",
      "        -0.0019,  0.0099, -0.0019, -0.0019, -0.0019,  0.0009, -0.0019, -0.0019],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0019, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019,  0.0041, -0.0019,\n",
      "        -0.0019, -0.0019, -0.0019, -0.0132, -0.0019, -0.0019, -0.0019, -0.0093],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0020, -0.0020,  0.0216, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020,\n",
      "        -0.0048,  0.1489, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020, -0.0174],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0020, -0.0020,  0.0192,  0.1347,  0.0140,  0.0010, -0.0020, -0.0020,\n",
      "        -0.0020, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0015,  0.0044, -0.0020,  0.0024, -0.0020, -0.0020, -0.0020, -0.0020,\n",
      "        -0.0310, -0.0004, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0021, -0.0021, -0.0021, -0.0021, -0.0021, -0.0021, -0.0021, -0.0021,\n",
      "        -0.0021, -0.0021, -0.0021,  0.0023, -0.0021,  0.0130,  0.0039, -0.0022],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0021,  0.0436,  0.0133], grad_fn=<SqueezeBackward1>)\n",
      "Epoch 17/20  Train: 6.842487e-04  Val: 3.245184e-04  Test: 2.619365e-04 ← best\n",
      "tensor([-0.0022, -0.0022, -0.0022, -0.0041, -0.0022, -0.0022, -0.0022, -0.0022,\n",
      "        -0.0022, -0.0022, -0.0156,  0.0247, -0.0022,  0.0042, -0.0155,  0.0002],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0022, -0.0022, -0.0022, -0.0032, -0.0022, -0.0022, -0.0022, -0.0022,\n",
      "        -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0311,  0.0178, -0.0023, -0.0023,  0.0094, -0.0023, -0.0023, -0.0023,\n",
      "        -0.0023,  0.0054, -0.0021, -0.0023, -0.0023, -0.0023, -0.0023, -0.0084],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0023, -0.0023, -0.0023, -0.0301, -0.0023, -0.0023, -0.0023, -0.0023,\n",
      "         0.0028, -0.0023, -0.0023, -0.0023, -0.0023,  0.0185, -0.0023, -0.0015],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0023, -0.0023,  0.0045,  0.0055, -0.0023, -0.0023, -0.0025, -0.0109,\n",
      "        -0.0023,  0.0154, -0.0023, -0.0023, -0.0023, -0.0023, -0.0023, -0.0130],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0183, -0.0022, -0.0155, -0.0022,  0.0091, -0.0022, -0.0022, -0.0022,\n",
      "         0.0076,  0.0117, -0.0022, -0.0022, -0.0022, -0.0022, -0.0022,  0.0591],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0022,  0.0124, -0.0022, -0.0022, -0.0022, -0.0022,  0.0455,  0.0057,\n",
      "         0.0236, -0.0022, -0.0022,  0.0058, -0.0022, -0.0035, -0.0022, -0.0022],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-2.1705e-03, -2.1705e-03, -2.1705e-03, -2.1705e-03,  8.5333e-05,\n",
      "        -2.1705e-03, -2.1705e-03, -1.7631e-02, -2.1705e-03, -2.1705e-03,\n",
      "        -2.1705e-03, -2.1705e-03, -2.2099e-02,  2.9965e-02, -2.1705e-03,\n",
      "        -2.9698e-03], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0021, -0.0021,  0.0112, -0.0021, -0.0021,  0.0501, -0.0021, -0.0108,\n",
      "        -0.0021, -0.0021, -0.0014, -0.0021, -0.0021, -0.0021, -0.0021, -0.0021],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0147, -0.0021, -0.0050, -0.0021, -0.0021, -0.0075,  0.0077, -0.0021,\n",
      "        -0.0021, -0.0021, -0.0021, -0.0021, -0.0021, -0.0021, -0.0021, -0.0021],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0021, -0.0021, -0.0021, -0.0021, -0.0021,  0.0397,  0.0070, -0.0021,\n",
      "        -0.0059, -0.0021, -0.0021, -0.0021, -0.0018, -0.0729, -0.0021, -0.0021],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-2.0539e-03, -2.0539e-03, -2.0539e-03, -2.0539e-03, -2.0539e-03,\n",
      "        -2.0539e-03, -5.6688e-03, -2.0539e-03, -2.0539e-03, -2.0539e-03,\n",
      "         2.3201e-02, -2.0539e-03, -3.9930e-03,  5.1329e-05, -2.0539e-03,\n",
      "         7.6400e-04], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0020, -0.0020, -0.0020, -0.0020, -0.0020,  0.0018, -0.0020, -0.0020,\n",
      "        -0.0020, -0.0020, -0.0020, -0.0020,  0.0422, -0.0020, -0.0020, -0.0736],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0020, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020, -0.0020,\n",
      "         0.0230,  0.0026, -0.0020, -0.0020,  0.0203, -0.0020, -0.0020, -0.0194],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0019, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019, -0.0106, -0.0019,\n",
      "        -0.0019, -0.0059, -0.0019, -0.0019, -0.0019, -0.0019,  0.0098, -0.0020],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0011, -0.0007, -0.0019, -0.0019, -0.0026, -0.0019, -0.0019,  0.0175,\n",
      "        -0.0019, -0.0019, -0.0019,  0.0215, -0.0019, -0.0019, -0.0019, -0.0019],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0130, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019,\n",
      "        -0.0019, -0.0019,  0.0116, -0.0019,  0.0023, -0.0019, -0.0019, -0.0019],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0019, -0.0019, -0.0019, -0.0067, -0.0019, -0.0019, -0.0019, -0.0019,\n",
      "        -0.0019, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019,  0.0136,  0.0007],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0019, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019,\n",
      "        -0.0019, -0.0019, -0.0019,  0.0040, -0.0019, -0.0019, -0.0074, -0.0019],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0019, -0.0019, -0.0031, -0.0019, -0.0019, -0.0019, -0.0019, -0.0019,\n",
      "        -0.0019, -0.0019, -0.0019,  0.0350, -0.0019, -0.0019, -0.0019, -0.0019],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0018, -0.0018, -0.0018,  0.0856, -0.0151, -0.0018, -0.0018, -0.0079,\n",
      "        -0.0333, -0.0018, -0.0018, -0.0018, -0.0018,  0.0125, -0.0018, -0.0018],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0018, -0.0018, -0.0081, -0.0018,  0.0012, -0.0018, -0.0018,  0.0208,\n",
      "         0.0233, -0.0136, -0.0018, -0.0018,  0.0029, -0.0018, -0.0018, -0.0018],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0133, -0.0014, -0.0018, -0.0018, -0.0018, -0.0018,  0.1109, -0.0018,\n",
      "        -0.0018, -0.0154, -0.0018, -0.0018, -0.0018, -0.0018, -0.0018, -0.0018],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0017, -0.0017, -0.0017, -0.0017, -0.0017, -0.0879, -0.0017,  0.0643,\n",
      "        -0.0057, -0.0017, -0.0020, -0.0017, -0.0017, -0.0017, -0.0017, -0.0017],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0021, -0.0011, -0.0017, -0.0112, -0.0017,  0.0018, -0.0017,  0.0006,\n",
      "         0.0221, -0.0017, -0.0017, -0.0017, -0.0017, -0.0017, -0.0017, -0.0017],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0017, -0.0126, -0.1555,  0.0119, -0.0017, -0.0017, -0.0017, -0.0017,\n",
      "        -0.0017, -0.0017,  0.0033,  0.0020, -0.0017, -0.0039, -0.0017,  0.0051],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.2702, -0.0016, -0.0016, -0.0100,  0.0168,  0.0240, -0.0016,  0.0040,\n",
      "        -0.0016, -0.0016, -0.0016, -0.0016, -0.0016, -0.0016, -0.0016, -0.0016],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0015, -0.0015, -0.0038, -0.0015,  0.0140, -0.0015, -0.0015, -0.0071,\n",
      "        -0.0015, -0.0015, -0.0015, -0.0015,  0.0636, -0.0015, -0.0015,  0.0017],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0014, -0.0014, -0.0014], grad_fn=<SqueezeBackward1>)\n",
      "Epoch 18/20  Train: 6.118542e-04  Val: 3.157331e-04  Test: 2.580031e-04 ← best\n",
      "tensor([-0.0013,  0.0115, -0.0013,  0.0011, -0.0013, -0.0013,  0.0066, -0.0013,\n",
      "        -0.0013, -0.0016, -0.0013,  0.0086, -0.0013, -0.0034, -0.0013, -0.0013],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0013,  0.0339, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,\n",
      "        -0.0013, -0.0013, -0.0013, -0.0013, -0.0013,  0.0110,  0.0203, -0.0013],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0092, -0.0485, -0.0012, -0.0012, -0.0012, -0.0012,  0.0004, -0.0012,\n",
      "         0.0207, -0.0012, -0.0012, -0.0012,  0.1011, -0.0012, -0.0012, -0.0012],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0011, -0.0011, -0.0011, -0.0011, -0.0011, -0.0049,  0.0022,  0.0119,\n",
      "        -0.0011, -0.0011, -0.0011,  0.0138, -0.0011, -0.0011, -0.0011, -0.0011],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0011, -0.0011, -0.0037, -0.0011, -0.0011, -0.0011, -0.0011, -0.0011,\n",
      "        -0.0011, -0.0011, -0.0011, -0.0011,  0.0264, -0.0011, -0.0011, -0.0011],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0010, -0.0010, -0.0043, -0.0552, -0.0010, -0.0010,  0.0622, -0.0010,\n",
      "        -0.0010, -0.0010, -0.0038, -0.0010, -0.0010, -0.0010,  0.0071, -0.0010],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0010, -0.0010, -0.0010, -0.0010,  0.0103, -0.0010, -0.0010, -0.0010,\n",
      "         0.1857, -0.0010, -0.0010, -0.0010, -0.0054, -0.0010, -0.0010, -0.0010],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0010, -0.0010, -0.0108, -0.0010, -0.0010, -0.0010,  0.0486, -0.0033,\n",
      "        -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0048, -0.0055],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0009,\n",
      "        -0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0009],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0009, -0.0009, -0.0009,  0.0011, -0.0009, -0.0009, -0.0009, -0.0009,\n",
      "        -0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0135, -0.0009,  0.0007],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0103, -0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0124, -0.0009,\n",
      "        -0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0083],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0009,\n",
      "        -0.0009, -0.0009, -0.0045, -0.0041,  0.0146, -0.0009, -0.0009, -0.0009],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0008, -0.0008,  0.0023, -0.0008, -0.0008, -0.0008,  0.0054, -0.0008,\n",
      "        -0.0008, -0.0008, -0.0008, -0.0008, -0.0008, -0.0008, -0.0008,  0.0074],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0008, -0.0008, -0.0008, -0.0008, -0.0008, -0.0008, -0.0008, -0.0136,\n",
      "        -0.0008, -0.0008, -0.0008, -0.0008, -0.0008, -0.0008, -0.0008, -0.0008],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0092, -0.0002, -0.0008, -0.0008, -0.0008, -0.0008, -0.0008, -0.0008,\n",
      "         0.0980, -0.0008,  0.0006, -0.0008, -0.0008,  0.0017, -0.0008, -0.0001],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0008, -0.0008, -0.0004, -0.0008, -0.0008, -0.0008,  0.0005, -0.0008,\n",
      "        -0.0008, -0.0008, -0.0008,  0.0113, -0.0008, -0.0008, -0.0008, -0.0008],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0008,  0.0027, -0.0008, -0.0988, -0.0008, -0.0008,  0.0201, -0.0008,\n",
      "        -0.0008, -0.0008,  0.0128, -0.0008, -0.0008, -0.0008, -0.0008, -0.0008],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0008, -0.0008, -0.0008, -0.0008, -0.0008, -0.0022, -0.0008, -0.0008,\n",
      "        -0.0014,  0.0059,  0.0085, -0.0024,  0.0033,  0.0187, -0.0008, -0.0008],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0007, -0.0007, -0.0007, -0.0007, -0.0007, -0.0007, -0.0007, -0.0007,\n",
      "        -0.0007, -0.0007, -0.0007, -0.0007, -0.0007, -0.0007, -0.0007, -0.0007],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0015,  0.0045, -0.0007, -0.0007, -0.0007, -0.0007, -0.0007, -0.0007,\n",
      "        -0.0007, -0.0148, -0.0007, -0.0007, -0.0007,  0.0091, -0.0007,  0.0152],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0007, -0.0006, -0.0007, -0.0007, -0.0213, -0.0007,  0.0033, -0.0007,\n",
      "         0.0038, -0.0007, -0.0007, -0.0013, -0.0007, -0.0007, -0.0007, -0.0007],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-6.0712e-04, -6.0712e-04, -2.2286e-03, -6.0712e-04, -6.0712e-04,\n",
      "         1.9811e-02, -6.0712e-04, -6.0712e-04, -6.0712e-04, -6.0712e-04,\n",
      "        -6.0712e-04, -6.0712e-04, -3.8028e-04, -6.0712e-04,  7.9805e-05,\n",
      "        -6.0712e-04], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0009,  0.0284, -0.0006,  0.0012,  0.0330, -0.0006,  0.0031, -0.0006,\n",
      "         0.0017, -0.0006, -0.0006, -0.0006, -0.0006,  0.0125, -0.0006, -0.0006],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0018, -0.0005, -0.0017, -0.0005, -0.0083, -0.0005, -0.0005,  0.0077,\n",
      "        -0.0005, -0.0005, -0.0005,  0.0239, -0.0154,  0.1205, -0.0005, -0.0005],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0149, -0.0005, -0.0005, -0.0005, -0.0005, -0.0005, -0.0005, -0.0005,\n",
      "        -0.0005, -0.0005, -0.0005, -0.0005, -0.0026, -0.0005, -0.0156,  0.0124],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0006, -0.0006, -0.0006, -0.0006,  0.0065, -0.0006,  0.0053, -0.0006,\n",
      "        -0.0006, -0.0006, -0.0006, -0.0006, -0.0006,  0.0222,  0.0598, -0.0105],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0036, -0.0006, -0.0006, -0.0006, -0.0006, -0.0006, -0.0006, -0.0006,\n",
      "        -0.0006, -0.0006, -0.0006, -0.0006,  0.0192,  0.0105, -0.0006, -0.0006],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0006, -0.0006, -0.0006, -0.0003,  0.0180, -0.0006, -0.0006, -0.0006,\n",
      "        -0.0006, -0.0006,  0.0109, -0.0200, -0.0006, -0.0006, -0.0073, -0.0006],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0014, -0.0007, -0.0007], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0007, -0.0070, -0.0007, -0.0016,  0.1287,  0.1174, -0.0129, -0.0007,\n",
      "        -0.0007, -0.0007, -0.0007, -0.0007, -0.0007, -0.0007, -0.0040, -0.0007],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0008, -0.0008, -0.0008, -0.0008,  0.0146,  0.0031, -0.0008, -0.0008,\n",
      "        -0.0008, -0.0008, -0.0008, -0.0008, -0.0008, -0.0008, -0.0008,  0.0083],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0009,\n",
      "        -0.0009, -0.0017,  0.0235, -0.0009,  0.1027, -0.0009, -0.0009, -0.0009],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0010,  0.0051, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,\n",
      "        -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,  0.0015, -0.0010, -0.0010],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0009, -0.0147, -0.0011, -0.0011, -0.0011, -0.0011, -0.0011, -0.0011,\n",
      "        -0.0011, -0.0003, -0.0079,  0.0049, -0.0011, -0.0011, -0.0011, -0.0011],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0011,  0.0285,  0.0138, -0.0011, -0.0011,  0.0034, -0.0011, -0.0011,\n",
      "        -0.0011, -0.0011, -0.0011, -0.0011, -0.0011,  0.0167, -0.0011, -0.0011],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0012, -0.0012, -0.0012, -0.0029, -0.0012, -0.0012, -0.0012, -0.0012,\n",
      "        -0.0012, -0.0012,  0.0088,  0.0065, -0.0012, -0.0012, -0.0012, -0.0012],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0013, -0.0030, -0.0013, -0.0013, -0.0013, -0.0013,  0.0260, -0.0013,\n",
      "        -0.0013,  0.0274, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0013, -0.0013,  0.0040, -0.0013, -0.0013, -0.0013,  0.0280,  0.0408,\n",
      "        -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0233, -0.0013, -0.0013],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0014, -0.0014, -0.1767, -0.0014, -0.0014, -0.0010,  0.0073, -0.0014,\n",
      "        -0.0014, -0.0014, -0.0014, -0.0014, -0.0359, -0.0014, -0.0014, -0.0014],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0014, -0.0014, -0.0014, -0.0014, -0.0014, -0.0014, -0.0014, -0.0014,\n",
      "        -0.0014, -0.0014, -0.0014, -0.0014, -0.0014, -0.0014, -0.0026,  0.0963],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0014, -0.0014, -0.0014, -0.0014, -0.0014,  0.0095,  0.0225, -0.0014,\n",
      "         0.0858, -0.0014, -0.0014, -0.0014, -0.0014, -0.0014, -0.0014, -0.0004],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0014, -0.0014, -0.0014, -0.0014, -0.0014, -0.0769, -0.0014, -0.0092,\n",
      "        -0.0014, -0.0014, -0.0014, -0.0014, -0.0014, -0.0014, -0.0014, -0.0014],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0014,  0.0168, -0.0014, -0.0014, -0.0014, -0.0014, -0.0014, -0.0014,\n",
      "        -0.0014, -0.0014, -0.0014, -0.0019, -0.0014, -0.0014, -0.0014, -0.0014],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0014, -0.0014, -0.0014, -0.0014,  0.1245,  0.0026, -0.0014, -0.0014,\n",
      "        -0.0014, -0.0087, -0.0032, -0.0014, -0.0014, -0.0014, -0.0014, -0.0014],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-1.3987e-03, -1.3987e-03, -1.3987e-03, -1.3987e-03, -1.3987e-03,\n",
      "        -1.3987e-03, -1.3987e-03, -1.3987e-03, -1.3987e-03, -1.3987e-03,\n",
      "         4.0779e-02, -1.3987e-03,  8.3162e-05, -1.6300e-02, -1.3987e-03,\n",
      "        -1.3987e-03], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0014,  0.0151, -0.0014, -0.0014,  0.0079, -0.0014, -0.0014, -0.0014,\n",
      "        -0.0014, -0.0014, -0.0014, -0.0014, -0.0034, -0.0014, -0.0014, -0.0014],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0014, -0.0014, -0.0145, -0.0014, -0.0014, -0.0014, -0.0014, -0.0014,\n",
      "        -0.0014, -0.0014, -0.0014, -0.0014, -0.0014, -0.0014, -0.0014, -0.0014],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 2.7516e-05, -1.3044e-03, -1.3044e-03, -1.3044e-03, -1.3044e-03,\n",
      "        -1.3044e-03, -1.1308e-01, -1.3044e-03, -1.7625e-02, -1.3044e-03,\n",
      "        -1.3044e-03, -1.3044e-03, -1.3044e-03, -1.3044e-03, -1.3044e-03,\n",
      "         2.7230e-03], grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0012, -0.0012, -0.0012, -0.0012, -0.0012,  0.0015, -0.0012, -0.0012,\n",
      "        -0.0012,  0.0084, -0.0012,  0.0001, -0.0050, -0.0012, -0.0012, -0.0012],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0011,  0.0132, -0.0011, -0.0011, -0.0011, -0.0011, -0.0011, -0.0011,\n",
      "        -0.0011, -0.0014, -0.0011, -0.0011, -0.0011, -0.0011, -0.0011, -0.0011],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([ 0.0279,  0.0054, -0.0011, -0.0006, -0.0011, -0.0011, -0.0011, -0.0011,\n",
      "        -0.0011, -0.0011, -0.0005, -0.0011, -0.0011, -0.0011, -0.0011, -0.0011],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,\n",
      "        -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,\n",
      "        -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0009, -0.0381, -0.0009, -0.0022, -0.0009, -0.0009, -0.0009, -0.0009,\n",
      "        -0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0151, -0.0009],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0009, -0.0009,  0.0097, -0.0009, -0.0009, -0.0012, -0.0009,  0.0026,\n",
      "        -0.0001, -0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0009],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0009,  0.0013, -0.0009, -0.0009, -0.0009,  0.0158, -0.0009, -0.0009,\n",
      "        -0.0009, -0.0059,  0.0045, -0.0009, -0.0009, -0.0009,  0.0275, -0.0009],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0009, -0.0034, -0.0009,\n",
      "        -0.0009, -0.0009, -0.0009,  0.0011,  0.0022, -0.0009, -0.0009, -0.0009],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([-0.0008, -0.0051, -0.0008], grad_fn=<SqueezeBackward1>)\n",
      "Epoch 20/20  Train: 4.577515e-04  Val: 2.987216e-04  Test: 2.568469e-04 ← best\n",
      "Best val loss: 0.00029872157028876245\n",
      "Final test loss (best model): 0.00025684686261229217\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# ---------- Hyperparams (tune as needed) ----------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 16\n",
    "num_epochs = 20               # same as your num_epochs_new\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-5\n",
    "patience = 7                  # early stopping patience on val loss\n",
    "clip_norm = 1.0\n",
    "\n",
    "# TCN architecture\n",
    "input_size = X_train_tensor.shape[-1]   # 10 in your case\n",
    "seq_len = X_train_tensor.shape[1]       # 20 in your case\n",
    "output_size = 1                         # predicting one value\n",
    "tcn_channels = [32, 32, 32]             # number of channels per level (small network)\n",
    "kernel_size = 3\n",
    "dropout = 0.3\n",
    "\n",
    "# ---------- TCN building blocks ----------\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super().__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "    def forward(self, x):\n",
    "        # x shape: (B, C, L + pad)\n",
    "        if self.chomp_size == 0:\n",
    "            return x\n",
    "        return x[:, :, : -self.chomp_size]\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, dilation, padding, dropout):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.utils.weight_norm(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                      stride=stride, padding=padding, dilation=dilation)\n",
    "        )\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = nn.utils.weight_norm(\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size,\n",
    "                      stride=stride, padding=padding, dilation=dilation)\n",
    "        )\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Init\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_size, tcn_channels, kernel_size=3, dropout=0.2, output_size=1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        num_levels = len(tcn_channels)\n",
    "        in_ch = input_size\n",
    "        for i in range(num_levels):\n",
    "            out_ch = tcn_channels[i]\n",
    "            dilation_size = 2 ** i\n",
    "            padding = (kernel_size - 1) * dilation_size\n",
    "            layers.append(TemporalBlock(in_ch, out_ch, kernel_size, stride=1,\n",
    "                                        dilation=dilation_size, padding=padding, dropout=dropout))\n",
    "            in_ch = out_ch\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "\n",
    "        # final head: takes last time-step's features (we'll index last element)\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(tcn_channels[-1], tcn_channels[-1] // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(tcn_channels[-1] // 2, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, seq_len, features)\n",
    "        # convert to (B, C, L) for Conv1d where C=input_size, L=seq_len\n",
    "        x = x.permute(0, 2, 1).contiguous()  # (B, features, seq_len)\n",
    "        y = self.tcn(x)                       # (B, channels, seq_len)\n",
    "        # take the last time-step features (causal conv => last index is final)\n",
    "        last = y[:, :, -1]                    # (B, channels)\n",
    "        out = self.linear(last)               # (B, output_size)\n",
    "        return out.squeeze(-1)\n",
    "\n",
    "# ---------- Instantiate model ----------\n",
    "model_tcn = TCN(input_size=input_size,\n",
    "                tcn_channels=tcn_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                dropout=dropout,\n",
    "                output_size=output_size).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_tcn.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "print(model_tcn)\n",
    "\n",
    "# ---------- Prepare data loaders with validation split ----------\n",
    "# Use last 20% of train set as validation (time-series split)\n",
    "val_size = int(0.2 * len(X_train_tensor))\n",
    "if val_size < 1:\n",
    "    raise ValueError(\"Training set too small for validation split. Reduce val fraction.\")\n",
    "\n",
    "X_val_tensor = X_train_tensor[-val_size:].to(device)\n",
    "y_val_tensor = y_train_tensor[-val_size:].to(device)\n",
    "\n",
    "X_train_sub = X_train_tensor[:-val_size]\n",
    "y_train_sub = y_train_tensor[:-val_size]\n",
    "\n",
    "train_dataset = TensorDataset(X_train_sub, y_train_sub)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# send test tensors to device (used only for logging at end)\n",
    "X_test_tensor = X_test_tensor.to(device)\n",
    "y_test_tensor = y_test_tensor.to(device)\n",
    "\n",
    "# ---------- Training with early stopping (based on validation loss) ----------\n",
    "best_val = float('inf')\n",
    "patience_counter = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "\n",
    "log_file_path = f'training_log_improved_TCN_{N}.txt'\n",
    "with open(log_file_path, 'w') as logf:\n",
    "    logf.write(\"TCN Model Training Log\\n\")\n",
    "    logf.write(\"=\"*60 + \"\\n\")\n",
    "    logf.write(f\"TCN channels: {tcn_channels}, kernel_size: {kernel_size}, dropout: {dropout}\\n\")\n",
    "    logf.write(\"=\"*60 + \"\\n\\n\")\n",
    "    logf.write(\"Epoch, Train Loss, Val Loss, Test Loss\\n\")\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model_tcn.train()\n",
    "        epoch_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            preds = model_tcn(batch_X)            # shape (B,)\n",
    "            print(preds)\n",
    "            loss = criterion(preds, batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model_tcn.parameters(), clip_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item() * batch_X.size(0)\n",
    "\n",
    "        avg_train_loss = epoch_loss / len(train_loader.dataset)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Validation (no grad)\n",
    "        model_tcn.eval()\n",
    "        with torch.no_grad():\n",
    "            val_preds = model_tcn(X_val_tensor)\n",
    "            val_loss = criterion(val_preds, y_val_tensor).item()\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            # Test loss for logging only\n",
    "            test_preds = model_tcn(X_test_tensor)\n",
    "            test_loss = criterion(test_preds, y_test_tensor).item()\n",
    "            test_losses.append(test_loss)\n",
    "\n",
    "        log_line = f\"{epoch},{avg_train_loss:.6e},{val_loss:.6e},{test_loss:.6e}\"\n",
    "        logf.write(log_line + \"\\n\")\n",
    "\n",
    "        # Early stopping / checkpoint\n",
    "        if val_loss < best_val - 1e-12:\n",
    "            best_val = val_loss\n",
    "            patience_counter = 0\n",
    "            best_epoch = epoch\n",
    "            torch.save(model_tcn.state_dict(), f'./models/best_tcn_{N}.pth')\n",
    "            best_note = \" ← best\"\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            best_note = \"\"\n",
    "            \n",
    "    \n",
    "\n",
    "        if epoch % 5 == 0 or patience_counter == 0:\n",
    "            print(f\"Epoch {epoch}/{num_epochs}  Train: {avg_train_loss:.6e}  Val: {val_loss:.6e}  Test: {test_loss:.6e}{best_note}\")\n",
    "            torch.save(model_tcn.state_dict(), f'./models/best_tcn_{N}_{epoch}.pth')\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch} (no improve for {patience} epochs). Best val: {best_val:.6e} at epoch {best_epoch}\")\n",
    "            break\n",
    "\n",
    "# ---------- Load best model and final test evaluation ----------\n",
    "model_tcn.load_state_dict(torch.load(f'./models/best_tcn_{N}.pth', map_location=device))\n",
    "model_tcn.eval()\n",
    "with torch.no_grad():\n",
    "    final_test_preds = model_tcn(X_test_tensor).cpu().numpy()\n",
    "    final_test_loss = criterion(torch.from_numpy(final_test_preds), y_test_tensor.cpu()).item()\n",
    "\n",
    "print(\"Best val loss:\", best_val)\n",
    "print(\"Final test loss (best model):\", final_test_loss)\n",
    "\n",
    "# Optionally: save losses / predictions for plotting\n",
    "np.savez(f'tcn_training_results_N{N}.npz',\n",
    "         train_losses=np.array(train_losses),\n",
    "         val_losses=np.array(val_losses),\n",
    "         test_losses=np.array(test_losses),\n",
    "         final_test_preds=final_test_preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61f621a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing epochs 1-50\n",
      "Train Loss at epoch 20: 0.000458\n",
      "Val Loss at epoch 20: 0.000299\n",
      "Test Loss at epoch 20: 0.000257\n",
      "Plot saved to: ./progress_report/media/training_loss_improved_TCN_10.pdf\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Load training log for current N\n",
    "log_path = f'training_log_improved_TCN_{N}.txt'\n",
    "with open(log_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Parse the log file written as CSV lines: epoch,train,val,test\n",
    "epochs = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    # Skip headers and separators\n",
    "    if (not line) or line.startswith('=') or line.startswith('TCN Model Training Log') or line.startswith('Epoch,'):\n",
    "        continue\n",
    "    # Accept lines that look like numeric CSV: e.g., 1,1.23e-03,1.11e-03,1.50e-03\n",
    "    parts = line.split(',')\n",
    "    if len(parts) == 4 and parts[0].strip().isdigit():\n",
    "        try:\n",
    "            epoch = int(parts[0].strip())\n",
    "            train_loss = float(parts[1].strip())\n",
    "            val_loss = float(parts[2].strip())\n",
    "            test_loss = float(parts[3].strip())\n",
    "            epochs.append(epoch)\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            test_losses.append(test_loss)\n",
    "        except ValueError:\n",
    "            # Skip any malformed line\n",
    "            continue\n",
    "\n",
    "# Crop data to only show up to epoch 50\n",
    "max_epoch = 50\n",
    "epochs_cropped = [e for e in epochs if e <= max_epoch]\n",
    "train_losses_cropped = train_losses[:len(epochs_cropped)]\n",
    "val_losses_cropped = val_losses[:len(epochs_cropped)]\n",
    "test_losses_cropped = test_losses[:len(epochs_cropped)]\n",
    "\n",
    "# Create formatter for y-axis to show n × 10^-3\n",
    "def formatter(x, pos):\n",
    "    return f'{x * 1e3:.1f}'\n",
    "\n",
    "# Plot training, validation and test loss (cropped to epoch 50)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(epochs_cropped, train_losses_cropped, label='Train Loss', linewidth=2)\n",
    "# ax.plot(epochs_cropped, val_losses_cropped, label='Val Loss', linewidth=2)\n",
    "ax.plot(epochs_cropped, test_losses_cropped, label='Test Loss', linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel(r'Loss ($\\times 10^{-3}$)'.replace('\\\\', '\\\\'), fontsize=12)\n",
    "ax.set_title(f'Training, Validation, and Test Loss - TCN (N={N})', fontsize=14)\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(formatter))\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'./progress_report/media/training_loss_improved_TCN_{N}.pdf')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Showing epochs 1-{max_epoch}\")\n",
    "if epochs_cropped:\n",
    "    print(f\"Train Loss at epoch {epochs_cropped[-1]}: {train_losses_cropped[-1]:.6f}\")\n",
    "    print(f\"Val Loss at epoch {epochs_cropped[-1]}: {val_losses_cropped[-1]:.6f}\")\n",
    "    print(f\"Test Loss at epoch {epochs_cropped[-1]}: {test_losses_cropped[-1]:.6f}\")\n",
    "print(f\"Plot saved to: ./progress_report/media/training_loss_improved_TCN_{N}.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
